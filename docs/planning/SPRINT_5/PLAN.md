# Sprint 5 Plan: Hardening, Packaging, and Documentation

**Sprint Duration:** 10 days  
**Sprint Goal:** Ship a production-ready, packaged tool with comprehensive documentation  
**Status:** ğŸ“‹ READY  
**Prepared:** November 6, 2025

---

## Overview

### What Sprint 5 Accomplishes

Sprint 5 turns nlp2mcp into a production-ready tool published on PyPI with polished documentation. Building on Sprint 4â€™s foundation (972 passing tests, 85%+ coverage, prep tasks complete), the sprint focuses on five pillars:
- **Bug-Free Core:** Resolve the min/max reformulation defect blocking PATH validation.
- **Solver Validation:** Exercise the PATH solver across all supported reformulations and document usage.
- **Production Quality:** Harden error handling, performance, and robustness on large models.
- **Easy Installation:** Deliver a PyPI package with automated release tooling.
- **User Documentation:** Ship tutorial, FAQ, troubleshooting guide, and API reference.

Alignment with Sprint 4 retrospective is preserved through prioritized checkpoints, the research-first workflow, and verified external dependencies (GAMS/PATH licensing).

---

## Success Metrics

### Functional Targets

1. âœ… Min/max reformulation fixed (5 research tests pass, PATH solves without spurious variables).
2. âœ… PATH validation complete (golden files run or documented, solver options captured).
3. âœ… Large models (250/500/1K vars) convert within benchmarks and stay under 500â€¯MB peak memory.
4. âœ… Error recovery system handles NaN/Inf and common authoring mistakes with actionable messaging.
5. âœ… PyPI package published; `pip install nlp2mcp` works on Python 3.10â€“3.12 with CLI entry point.
6. âœ… Tutorial produced with tested walkthrough examples.
7. âœ… FAQ covers â‰¥20 real questions with troubleshooting guidance.
8. âœ… Release automation in place (version bumping, changelog generation, GitHub Actions) and CHANGELOG.md updated.
9. âœ… API documentation site (Sphinx) published with docstring coverage and deployment script.

### Quality Targets

1. âœ… All existing tests (â‰¥972) green; no regressions.
2. âœ… New code maintains â‰¥85â€¯% coverage.
3. âœ… Known Unknowns resolved or formally deferred with justification.
4. âœ… Tooling clean: mypy 0 errors, ruff 0 errors, black-formatted.
5. âœ… PATH golden suite achieves â‰¥90â€¯% success (remaining failures documented).
6. âœ… Fresh-venv install sanity check passes on supported platforms.

### Integration Targets

1. âœ… Public API stable relative to Sprints 1â€“4.
2. âœ… Generated MCPs compile cleanly in GAMS.
3. âœ… PATH solves generated MCPs post-fix.
4. âœ… Large-model fixtures pass quality gates (performance + correctness).

---

## Day-by-Day Plan

Each day lists goals, task breakdowns with the driving Known Unknowns, deliverables, acceptance criteria, integration risks, and a dedicated **Follow-On Research Items** section that keeps research work separate from execution tasks.

### Day 1 â€“ Min/Max Bug Fix: Research & Design

**Priority:** 1 (Critical bug)â€ƒ**Effort:** 8â€¯hâ€ƒ**Dependencies:** Sprint 4 code, Unknownâ€¯1.1 findings  
**Goals:** Understand min/max failure, design KKT fix, scaffold tests and detection logic.

- **Taskâ€¯1.1 â€“ Review Unknownâ€¯1.1 (DISPROVEN)** (1â€¯h)  
  Confirm Strategyâ€¯1 (auxiliary variables) is required; digest research analysis.

- **Taskâ€¯1.2 â€“ KKT Assembly Design** (2â€¯h)  
  **Related Unknowns:** 1.2 (ğŸ”), 1.4 (ğŸ”)  
  Map required updates in `src/kkt/assemble.py`, produce design doc with affected code paths.

- **Taskâ€¯1.3 â€“ Regression Tests** (1â€¯h)  
  Port five research cases to `tests/unit/kkt/test_minmax_fix.py`, mark xfail, capture expected behaviour.

- **Taskâ€¯1.4 â€“ Detection Logic** (2â€¯h)  
  **Related Unknown:** 1.2 (ğŸ”)  
  **Implementation Notes:** Fully implemented with `detects_objective_minmax()` function using worklist algorithm for transitive dependency tracing. Module location: `src/ir/minmax_detection.py` (238 lines). Test coverage: 100% (29 tests in `tests/unit/ir/test_minmax_detection.py`). Key architectural decision: Pure IR-layer implementation avoiding circular KKT dependency.
  Add AST inspection for objective-defining min/max chains with unit tests covering aliasing scenarios.

- **Taskâ€¯1.5 â€“ Assembly Scaffolding** (2â€¯h)  
  **Related Unknown:** 1.4 (ğŸ”)  
  Implement initial multiplier inclusion plus targeted logging; ensure build succeeds.

**Deliverables:** design memo, xfailed test suite, detection module + tests, assembly prototype.  
**Acceptance:** tests authored, detection coverage 100â€¯%, build clean, design reviewed.  

**Status:** âœ… COMPLETE (November 6, 2025)
**Risks:** KKT regression (mitigate via regression suite), detection misses edge cases (mitigate via research test coverage).

**Follow-On Research Items**
- Unknown 1.2 â€“ Objective min/max detection (âœ… COMPLETE) â†’ resolved during Day 1 implementation.
  - **Summary:** Algorithm fully implemented in `src/ir/minmax_detection.py` with 100% test coverage (29 passing tests)
  - **Key Function:** `detects_objective_minmax(model_ir)` traces from objective through dependency chain
  - **Algorithm:** Worklist-based graph traversal with cycle detection, handles arbitrary-depth chains
  - **Test Coverage:** Direct min/max, 1-hop chains, 2-hop chains, nested min/max, negative cases
  - **Limitation:** Indexed objectives not yet supported (deferred - no current use cases)
  - **Performance:** O(V+E) graph traversal, <1ms for typical models
  - **Architecture:** Pure IR-layer implementation, no KKT dependency (avoids circular import)
- Unknownâ€¯1.4 â€“ KKT assembly adjustments (ğŸ”) â†’ resolve by EOD Dayâ€¯2.

---

### Day 2 â€“ Min/Max Bug Fix: Implementation & Testing

**Priority:** 1â€ƒ**Effort:** 8â€¯hâ€ƒ**Dependencies:** Dayâ€¯1 design  
**Goals:** Finish implementation, validate with PATH, clean up tests.

- **Taskâ€¯2.1 â€“ Finalize Assembly** (3â€¯h)  
  **Unknown:** 1.4 (ğŸ”)  
  Complete multiplier integration, ensure indexed equations handled, add inline docs.

- **Taskâ€¯2.2 â€“ Debug Research Cases** (2â€¯h)  
  Iterate on failing tests until generated MCPs are correct.

- **Taskâ€¯2.3 â€“ PATH Validation Smoke** (2â€¯h)  
  **Unknown:** 1.5 (ğŸ”)  
  Run all five min/max MCPs through PATH, experiment with options if convergence issues surface.

- **Taskâ€¯2.4 â€“ Remove xfail** (0.5â€¯h)  
  Drop xfail markers, annotate fixes in tests.

- **Taskâ€¯2.5 â€“ Regression Sweep** (0.5â€¯h)  
  Run full pytest suite, address any fallout.

**Deliverables:** finalized assembly, green min/max tests, PATH validation results, tidy test suite.  
**Acceptance:** five cases pass + PATH solves, full suite green, coverage â‰¥85â€¯%, mypy/ruff clean.  
**Risks:** PATH non-convergence (use Unknownâ€¯1.5 mitigation), regression outside min/max (full suite).

**Follow-On Research Items**
- Unknownâ€¯1.5 â€“ PATH option tuning (ğŸ”) â†’ resolve by EOD Dayâ€¯2.

---

### Day 3 â€“ PATH Validation & Checkpointâ€¯1

**Priority:** 2â€ƒ**Effort:** 7â€¯h + 1â€¯h checkpointâ€ƒ**Dependencies:** Dayâ€¯2  
**Goals:** Run complete PATH suite, document solver usage, complete Checkpointâ€¯1.

- **Taskâ€¯3.1 â€“ Execute Validation Suite** (2â€¯h)  
  Run PATH validation tests; capture status/residuals.

- **Taskâ€¯3.2 â€“ Investigate Failures** (2â€¯h)  
  **Unknown:** 2.1 (ğŸ”)  
  Analyse Model Statusâ€¯5 cases, differentiate expected model infeasibility vs bugs.

- **Taskâ€¯3.3 â€“ Document PATH Usage** (2â€¯h)  
  **Unknowns:** 2.2 (ğŸ”), 2.3 (ğŸ”)  
  Author `docs/PATH_SOLVER.md`, update user guide with solver options and interpretation.

- **Taskâ€¯3.4 â€“ Test Suite Hygiene** (1â€¯h)  
  Adjust skip/xfail expectations, embed solver option defaults.

- **Checkpointâ€¯1** (1â€¯h)  
  Review feature completeness, unknown status, coverage, lint/test health; decide GO/NO-GO for Dayâ€¯4+.

**Deliverables:** PATH results log, documentation updates, stable validation suite, checkpoint report.  
**Acceptance:** â‰¥90â€¯% PATH success, failures documented, PATH guide published, checkpoint GO with no blockers.  
**Risks:** Solver option gaps (document + mitigation), new unknowns (capture in follow-on list).

**Follow-On Research Items**
- Unknownâ€¯2.1 â€“ Model Statusâ€¯5 diagnostics (ğŸ”) â†’ Dayâ€¯3.  
- Unknownâ€¯2.2 â€“ Document PATH options (ğŸ”) â†’ Dayâ€¯3.  
- Unknownâ€¯2.3 â€“ PATH solution quality guidance (ğŸ”) â†’ Dayâ€¯3.  
- Unknownâ€¯2.4 â€“ PATH in CI/CD (ğŸ”, deferred to Sprintâ€¯6).

---

### Day 4 â€“ Production Hardening: Error Recovery

**Priority:** 3.1â€ƒ**Effort:** 8â€¯hâ€ƒ**Dependencies:** None  
**Goals:** Harden numerical handling, validation, and messaging.

- **Taskâ€¯4.1 â€“ Numerical Guardrails** (2â€¯h)  
  **Unknown:** 3.4 (ğŸ”)  
  Detect NaN/Inf post-operation, surface contextual `NumericalError`.

- **Taskâ€¯4.2 â€“ Model Validation Pass** (2â€¯h)  
  **Unknown:** 3.5 (ğŸ”)  
  Add pre-assembly validation for undefined symbols, circular deps, type mismatches, missing objectives.

- **Taskâ€¯4.3 â€“ Message Improvements** (2â€¯h)  
  Enhance errors with location, context, remediation pointers.

- **Taskâ€¯4.4 â€“ Recovery Tests** (2â€¯h)  
  Build â‰¥20 integration tests covering failure scenarios and verifying guidance.

**Deliverables:** NaN/Inf hooks, validation module, improved error catalogue, recovery test suite.  
**Acceptance:** Validation catches targeted mistakes, error messages actionable, â‰¥20 new tests passing, coverage â‰¥85â€¯%.  
**Risks:** False positives from validation (allow opt-out flag), perf hit (profile, optimise).

**Follow-On Research Items**
- Unknownâ€¯3.4 â€“ Numerical handling approach (ğŸ”) â†’ Dayâ€¯4.  
- Unknownâ€¯3.5 â€“ Validation design (ğŸ”) â†’ Dayâ€¯4.

---

### Day 5 â€“ Production Hardening: Large Models & Memory

**Priority:** 3.2 & 3.3â€ƒ**Effort:** 8â€¯hâ€ƒ**Dependencies:** Large-model fixtures from prep  
**Goals:** Benchmark large-model throughput, profile time/memory, codify targets.

- **Taskâ€¯5.1 â€“ Fixture Runs** (2â€¯h)  
  Execute 250/500/1000 variable models, record timings and correctness.

- **Taskâ€¯5.2 â€“ Time Profiling** (2â€¯h)  
  Break down phase runtimes with cProfile/line-profiler.

- **Taskâ€¯5.3 â€“ Memory Profiling** (2â€¯h)  
  **Unknown:** 3.3 (ğŸ”)  
  Measure peak usage, apply sparse structures or generators if >500â€¯MB.

- **Taskâ€¯5.4 â€“ Benchmark Suite** (2â€¯h)  
  Add `tests/benchmarks/test_large_models.py`, wire optional slow CI targets.

**Deliverables:** Timing + memory reports, benchmark tests, documented targets.  
**Acceptance:** Fixtures within targets, memory â‰¤500â€¯MB, benchmarks pass, no regressions vs Sprintâ€¯4.  
**Risks:** Parser/AD regressions (progressive testing), memory spikes (apply optimisation).

**Follow-On Research Items**
- Unknownâ€¯3.3 â€“ Memory optimisation tactics (ğŸ”) â†’ Dayâ€¯5.

---

### Day 6 â€“ Production Hardening: Edge Cases & Checkpointâ€¯2

**Priority:** 3â€ƒ**Effort:** 7â€¯h + 1â€¯h checkpointâ€ƒ**Dependencies:** Daysâ€¯4â€“5  
**Goals:** Cover critical edge cases, document limits, hold Checkpointâ€¯2.

- **Taskâ€¯6.1 â€“ Edge Case Suite** (3â€¯h)  
  **Unknown:** 3.2 (ğŸ”)  
  Implement â‰¥20 cases across bounds, degeneracy, zero Jacobians, circular references, empty sets.

- **Taskâ€¯6.2 â€“ Boundary Testing** (2â€¯h)  
  Stress test dimensional limits, nest depth, identifier length; record constraints.

- **Taskâ€¯6.3 â€“ Message Validation** (1â€¯h)  
  Review error clarity from new cases; patch gaps.

- **Taskâ€¯6.4 â€“ Limitations Doc** (1â€¯h)  
  Author `docs/LIMITATIONS.md`, link from README and user guide.

- **Checkpointâ€¯2** (1â€¯h)  
  Validate progress vs plan, quality metrics, scope adjustments, readiness for packaging.

**Deliverables:** Edge-case tests, boundary write-up, LIMITATIONS doc, checkpoint report.  
**Acceptance:** â‰¥20 tests pass/fail gracefully, documented limits published, checkpoint GO for Dayâ€¯7.  
**Risks:** Newly uncovered critical issues (surface early, feed into Dayâ€¯10 buffer).

**Follow-On Research Items**
- Unknownâ€¯3.2 â€“ Edge-case catalogue (ğŸ”) â†’ Dayâ€¯6.

---

### Day 7 â€“ PyPI Packaging: Configuration & Build

**Priority:** 4â€ƒ**Effort:** 8â€¯hâ€ƒ**Dependencies:** None  
**Goals:** Select build backend, configure packaging metadata, validate local installs.

- **Taskâ€¯7.1 â€“ Build System Decision** (1â€¯h)  
  **Unknown:** 4.1 (ğŸ”)  
  Compare setuptools/hatch/flit; adopt hatch for modern workflow.

- **Taskâ€¯7.2 â€“ `pyproject.toml` Setup** (2â€¯h)  
  **Unknown:** 4.2 (ğŸ”)  
  Populate PEPâ€¯621 metadata, dependencies, optional extras.

- **Taskâ€¯7.3 â€“ CLI Entry Point** (1â€¯h)  
  Configure console script in `pyproject.toml`; verify CLI usage text.

- **Taskâ€¯7.4 â€“ Wheel Build** (1â€¯h)  
  Produce wheel via `python -m build`, inspect distribution.

- **Taskâ€¯7.5 â€“ Local Install QA** (2â€¯h)  
  Smoke test install/uninstall in fresh venv, run CLI on sample models.

- **Taskâ€¯7.6 â€“ Multi-Platform Check** (1â€¯h)  
  **Unknown:** 4.3 (ğŸ”)  
  Exercise tox across Python 3.10â€“3.12 on macOS; note issues for Dayâ€¯8 CI matrix.

**Deliverables:** pyproject metadata, built wheel, install report, multi-platform notes.  
**Acceptance:** Wheel build passes, CLI operational post-install, dependencies resolved, python matrix smoke green.  
**Risks:** Missing package data (validate wheel contents), CLI entry misconfigurations (smoke test).

**Follow-On Research Items**
- Unknownâ€¯4.1 â€“ Build backend choice (ğŸ”) â†’ Dayâ€¯7.  
- Unknownâ€¯4.2 â€“ PyPI metadata checklist (ğŸ”) â†’ Dayâ€¯7.  
- Unknownâ€¯4.3 â€“ Multi-platform strategy (ğŸ”) â†’ Dayâ€¯7.

---

### Day 8 â€“ PyPI Release Automation & Checkpointâ€¯3

**Priority:** 4â€ƒ**Effort:** 7â€¯h + 1â€¯h checkpointâ€ƒ**Dependencies:** Dayâ€¯7  
**Goals:** Automate versioning/changelog, configure publish workflow, push to TestPyPI, update docs/CHANGELOG, run Checkpointâ€¯3.

- **Taskâ€¯8.1 â€“ Version Strategy** (0.5â€¯h)  
  **Unknown:** 4.4 (ğŸ”)  
  Document semantic version path (0.4.0 launch â†’ 1.0.0 readiness).

- **Taskâ€¯8.2 â€“ Version Bump Script** (1.5â€¯h)  
  Create `scripts/bump_version.py`, integrate with workflow.

- **Taskâ€¯8.3 â€“ Changelog Generator** (1.5â€¯h)  
  Build `scripts/generate_changelog.py` (Keep a Changelog format) and automation hook.

- **Taskâ€¯8.4 â€“ GitHub Actions Workflow** (1.5â€¯h)  
  Compose `.github/workflows/publish-pypi.yml` with build/test/publish steps (dry-run on branch).

- **Taskâ€¯8.5 â€“ TestPyPI Publish** (0.5â€¯h)  
  Upload artefacts via `twine`, verify listing.

- **Taskâ€¯8.6 â€“ TestPyPI Install QA** (0.5â€¯h)  
  Install from TestPyPI in clean venv, run CLI.

- **Taskâ€¯8.7 â€“ Release Docs** (0.5â€¯h)  
  Draft/refresh `RELEASING.md` with automated steps and manual checklist.

- **Taskâ€¯8.8 â€“ README Update** (0.5â€¯h)  
  Document `pip install`, add PyPI badge, verify quick-start.

- **Taskâ€¯8.9 â€“ CHANGELOG Update** (0.5â€¯h)  
  Record Sprintâ€¯5 highlights using automation output; manually sanity check.

- **Checkpointâ€¯3** (1â€¯h)  
  Confirm Priorityâ€¯1-4 completion, release readiness, doc readiness; GO/NO-GO for Dayâ€¯9 documentation.

**Deliverables:** Version/changelog scripts, CI workflow, TestPyPI release, updated README & CHANGELOG, checkpoint report.  
**Acceptance:** Automation scripts tested, workflow passes, TestPyPI install validated, docs updated, checkpoint GO.  
**Risks:** Secret misconfig (dry-run, manual fallback), automation bugs (local tests before CI).

**Follow-On Research Items**
- Unknownâ€¯4.4 â€“ Versioning plan (ğŸ”) â†’ Dayâ€¯8.

---

### Day 9 â€“ Documentation Push (Tutorial, FAQ, Troubleshooting, API Site)

**Priority:** 5â€ƒ**Effort:** 8â€¯hâ€ƒ**Dependencies:** Daysâ€¯1â€“8 complete  
**Goals:** Deliver complete end-user documentation, publish API reference.

- **Taskâ€¯9.1 â€“ Tutorial Outline** (1â€¯h)  
  **Unknown:** 5.2 (ğŸ”)  
  Finalise sections, assets, and examples.

- **Taskâ€¯9.2 â€“ Tutorial Authoring** (3â€¯h)  
  Produce `docs/TUTORIAL.md` with runnable samples, screenshots/diagrams, cross-links.

- **Taskâ€¯9.3 â€“ FAQ Build** (1.5â€¯h)  
  Source â‰¥20 real questions from testing/edges/retro, structure by theme, provide answers + links.

- **Taskâ€¯9.4 â€“ Troubleshooting Upgrade** (0.5â€¯h)  
  **Unknown:** 5.3 (ğŸ”)  
  Rework `docs/TROUBLESHOOTING.md` with Problem â†’ Diagnosis â†’ Solution sections and error snippets.

- **Taskâ€¯9.5 â€“ API Documentation Site** (2â€¯h)  
  **Unknowns:** 5.1 (âœ…), 5.4 (ğŸ”)  
  Configure Sphinx (autodoc/type hints), generate HTML, prep GitHub Pages/ReadTheDocs deployment.

**Deliverables:** Tutorial, FAQ, enhanced troubleshooting guide, Sphinx site, deployment steps.  
**Acceptance:** Examples verified, â‰¥20 FAQ entries, Sphinx build succeeds, docs cross-linked, no broken links.  
**Risks:** Documentation scope overrun (use Dayâ€¯10 buffer), Sphinx dependencies (lock requirements early).

**Follow-On Research Items**
- Unknownâ€¯5.1 â€“ Tooling decision (âœ… resolved: Sphinx).  
- Unknownâ€¯5.2 â€“ Tutorial scope (ğŸ”) â†’ Dayâ€¯9.  
- Unknownâ€¯5.3 â€“ Troubleshooting depth (ğŸ”) â†’ Dayâ€¯9.  
- Unknownâ€¯5.4 â€“ API detail level (ğŸ”) â†’ Dayâ€¯9.

---

### Day 10 â€“ Polish & Buffer

**Priority:** Bufferâ€ƒ**Effort:** 8â€¯hâ€ƒ**Dependencies:** Daysâ€¯1â€“9  
**Goals:** Close outstanding work, perform quality sweep, prep retrospective.

- **Taskâ€¯10.1 â€“ Backlog Burn-down** (4â€¯h)  
  Finish any open acceptance criteria (priority: critical â†’ high â†’ medium â†’ low).

- **Taskâ€¯10.2 â€“ Final QA Pass** (2â€¯h)  
  Run full tests, coverage, mypy, ruff, black; verify docs links, package install sanity.

- **Taskâ€¯10.3 â€“ Retrospective Prep** (1â€¯h)  
  Collect metrics (tests, coverage, performance, release stats), draft talking points/action items.

- **Taskâ€¯10.4 â€“ Deliverables Checklist** (1â€¯h)  
  Ensure all Sprintâ€¯5 outputs complete, sign off for demo/release.

**Deliverables:** Cleared backlog, QA evidence, retro notes, completion checklist.  
**Acceptance:** Critical/high items complete, all tests pass, coverage â‰¥85â€¯%, docs + release assets verified, retro packet ready.  
**Risks:** Late surprises (buffer absorbs), remaining low-priority tasks may slip (document deferrals).

**Follow-On Research Items**
- Critical/high unknowns resolved Daysâ€¯1â€“9; any new low-priority discoveries are flagged for Sprintâ€¯6 planning.

---

## Risk Management

| Risk | Prob. | Impact | Mitigation | Contingency |
| --- | --- | --- | --- | --- |
| Min/max fix complexity | Medium | High | Dedicated Daysâ€¯1â€“2, research complete, checkpoints | Scope to common cases, defer edge scenarios |
| PATH licensing/access | Low | High | Dependencies verified in prep, manual path if CI unavailable | Run manual solver sessions, document limits |
| Release automation defects | Medium | Medium | Local script tests, dry-run workflow, manual checklist | Fall back to manual release process |
| Performance misses targets | Low | Medium | Benchmarks + profiling Dayâ€¯5, documented baselines | Publish current metrics, schedule optimisation |
| Documentation overrun | Medium | Low | Full Dayâ€¯9 allocation, Dayâ€¯10 buffer | Ship reduced docs, refine next sprint |
| Edge cases unveil blockers | Low | High | Systematic testing Dayâ€¯6, early checkpoint | Document + schedule remediation |
| Sphinx build instability | Low | Low | Lock dependencies, early build dry run | Defer API site to Sprintâ€¯6 if required |

---

## Dependencies

```
Day 1 â†’ Day 2 â†’ Day 3 â†’ (Checkpt 1 GO)
       â†˜ï¸ Day 4 â†’ Day 5 â†’ Day 6 â†’ (Checkpt 2 GO)
                           â†˜ï¸ Day 7 â†’ Day 8 â†’ (Checkpt 3 GO) â†’ Day 9 â†’ Day 10
```

**External:**  
- GAMS/PATH licenses (validated during prep) for Daysâ€¯2â€“3 PATH work.  
- Large-model fixtures from prep Taskâ€¯8 feed Dayâ€¯5 benchmarks.  
- PyPI/TestPyPI credentials for Dayâ€¯8 automation.  
- Documentation tooling (Sphinx, MkDocs legacy docs) configured through prep tasks.

---

## Sprint Success Definition

**Minimum (B):** Min/max fix, PATH validation, large-model benchmarks, PyPI build, tutorial, â‰¥1000 tests, â‰¥80â€¯% coverage.  
**Target (A):** Minimum plus error recovery suite, memory tuning, edge-case coverage, TestPyPI publish, FAQ, release automation, â‰¥85â€¯% coverage, checkpoints passed.  
**Stretch (A+):** Target plus production PyPI release, API site deployed, performance exceeds targets, zero deferred critical items, Sprint complete by Dayâ€¯9.

---

## Known Unknowns Tracking

Active unknowns, ownership, and target resolution day:

- **Category 1 (Min/Max):** 1.2, 1.4, 1.5 â†’ Daysâ€¯1â€“2.  
- **Category 2 (PATH):** 2.1, 2.2, 2.3 â†’ Dayâ€¯3; 2.4 deferred to Sprintâ€¯6.  
- **Category 3 (Hardening):** 3.2 â†’ Dayâ€¯6; 3.3 â†’ Dayâ€¯5; 3.4â€“3.5 â†’ Dayâ€¯4.  
- **Category 4 (Packaging):** 4.1â€“4.3 â†’ Dayâ€¯7; 4.4 â†’ Dayâ€¯8.  
- **Category 5 (Docs):** 5.2â€“5.4 â†’ Dayâ€¯9 (5.1 resolved: Sphinx).  
- Any new discoveries are logged during checkpoints and evaluated for mitigation or deferral.

---

## Checkpoint Cadence

- **Checkpointâ€¯0 (Prep, complete):** Dependencies + retrospective alignment.  
- **Checkpointâ€¯1 (Dayâ€¯3):** Validate Priorityâ€¯1â€“2 execution, unblock hardening.  
- **Checkpointâ€¯2 (Dayâ€¯6):** Confirm production hardening outcomes before packaging.  
- **Checkpointâ€¯3 (Dayâ€¯8):** Release readiness prior to documentation push.

Each checkpoint uses templates in `docs/process/CHECKPOINT_TEMPLATES.md` and explicitly records GO/NO-GO decisions plus remediation plans if needed.

---

## Definition of Done

Sprint 5 concludes when:
- All Success Metrics targets are met or deviations are documented and approved.
- Release artefacts (package, automation, docs) are published and verified.
- CHANGELOG.md reflects Sprintâ€¯5 changes.
- Retro inputs compiled, and outstanding items are scheduled or deferred with rationale.

Upon completion, update CHANGELOG.md and tag the release per the automated workflow.***
