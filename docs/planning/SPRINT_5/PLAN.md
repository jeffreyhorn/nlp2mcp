# Sprint 5 Plan: Hardening, Packaging, and Documentation

**Sprint Duration:** 10 days
**Sprint Goal:** Ship a production-ready, packaged tool with comprehensive documentation
**Status:** ğŸ“‹ READY
**Prepared:** November 6, 2025

---

## Overview

### What Sprint 5 Accomplishes

Sprint 5 turns nlp2mcp into a production-ready tool published on PyPI with polished documentation. Building on Sprint 4â€™s foundation (972 passing tests, 85%+ coverage, prep tasks complete), the sprint focuses on five pillars:
- **Bug-Free Core:** Resolve the min/max reformulation defect blocking PATH validation.
- **Solver Validation:** Exercise the PATH solver across all supported reformulations and document usage.
- **Production Quality:** Harden error handling, performance, and robustness on large models.
- **Easy Installation:** Deliver a PyPI package with automated release tooling.
- **User Documentation:** Ship tutorial, FAQ, troubleshooting guide, and API reference.

Alignment with Sprint 4 retrospective is preserved through prioritized checkpoints, the research-first workflow, and verified external dependencies (GAMS/PATH licensing).

---

## Success Metrics

### Functional Targets

1. âœ… Min/max reformulation fixed (5 research tests pass, PATH solves without spurious variables).
2. âœ… PATH validation complete (golden files run or documented, solver options captured).
3. âœ… Large models (250/500/1K vars) convert within benchmarks and stay under 500â€¯MB peak memory.
4. âœ… Error recovery system handles NaN/Inf and common authoring mistakes with actionable messaging.
5. âœ… PyPI package published; `pip install nlp2mcp` works on Python 3.11â€“3.12 with CLI entry point.
6. âœ… Tutorial produced with tested walkthrough examples.
7. âœ… FAQ covers â‰¥20 real questions with troubleshooting guidance.
8. âœ… Release automation in place (version bumping, changelog generation, GitHub Actions) and CHANGELOG.md updated.
9. âœ… API documentation site (Sphinx) published with docstring coverage and deployment script.

### Quality Targets

1. âœ… All existing tests (â‰¥972) green; no regressions.
2. âœ… New code maintains â‰¥85â€¯% coverage.
3. âœ… Known Unknowns resolved or formally deferred with justification.
4. âœ… Tooling clean: mypy 0 errors, ruff 0 errors, black-formatted.
5. âœ… PATH golden suite achieves â‰¥90â€¯% success (remaining failures documented).
6. âœ… Fresh-venv install sanity check passes on supported platforms.

### Integration Targets

1. âœ… Public API stable relative to Sprints 1â€“4.
2. âœ… Generated MCPs compile cleanly in GAMS.
3. âœ… PATH solves generated MCPs post-fix.
4. âœ… Large-model fixtures pass quality gates (performance + correctness).

---

## Day-by-Day Plan

Each day lists goals, task breakdowns with the driving Known Unknowns, deliverables, acceptance criteria, integration risks, and a dedicated **Follow-On Research Items** section that keeps research work separate from execution tasks.

### Day 1 â€“ Min/Max Bug Fix: Research & Design

**Priority:** 1 (Critical bug)â€ƒ**Effort:** 8â€¯hâ€ƒ**Dependencies:** Sprint 4 code, Unknownâ€¯1.1 findings
**Goals:** Understand min/max failure, design KKT fix, scaffold tests and detection logic.

- **Taskâ€¯1.1 â€“ Review Unknownâ€¯1.1 (DISPROVEN)** (1â€¯h)
  Confirm Strategyâ€¯1 (auxiliary variables) is required; digest research analysis.

- **Taskâ€¯1.2 â€“ KKT Assembly Design** (2â€¯h)
  **Related Unknowns:** 1.2 (ğŸ”), 1.4 (ğŸ”)
  Map required updates in `src/kkt/assemble.py`, produce design doc with affected code paths.

- **Taskâ€¯1.3 â€“ Regression Tests** (1â€¯h)
  Port five research cases to `tests/unit/kkt/test_minmax_fix.py`, mark xfail, capture expected behaviour.

- **Taskâ€¯1.4 â€“ Detection Logic** (2â€¯h)
  **Related Unknown:** 1.2 (ğŸ”)
  **Implementation Notes:** Fully implemented with `detects_objective_minmax()` function using worklist algorithm for transitive dependency tracing. Module location: `src/ir/minmax_detection.py` (271 lines). Test coverage: 100% (29 tests in `tests/unit/ir/test_minmax_detection.py`). Key architectural decision: Pure IR-layer implementation avoiding circular KKT dependency.
  Add AST inspection for objective-defining min/max chains with unit tests covering aliasing scenarios.

- **Taskâ€¯1.5 â€“ Assembly Scaffolding** (2â€¯h)
  **Related Unknown:** 1.4 (âœ…)
  Implement initial multiplier inclusion plus targeted logging; ensure build succeeds.
  **Implementation Notes:**
  - **Scaffolding COMPLETE:** Comprehensive TODO comments and logging framework are already in place in `src/kkt/assemble.py`.
  - **Architecture Analysis:** No algorithmic changes are needed. KKT assembly is Jacobian-driven and automatically includes ALL equality constraints.
  - **Day 2 Work:** Simplified to (1) adding the reformulation call to the pipeline, and (2) enabling debug logging.
  - See lines 115-261 in `assemble.py` for detailed scaffolding.

**Deliverables:** design memo, xfailed test suite, detection module + tests, assembly prototype.
**Acceptance:** tests authored, detection coverage 100â€¯%, build clean, design reviewed.

**Status:** âœ… COMPLETE (November 6, 2025)
**Risks:** KKT regression (mitigate via regression suite), detection misses edge cases (mitigate via research test coverage).

**Follow-On Research Items**
- Unknown 1.2 â€“ Objective min/max detection (âœ… COMPLETE) â†’ resolved during Day 1 implementation.
  - **Summary:** Algorithm fully implemented in `src/ir/minmax_detection.py` with 100% test coverage (29 passing tests)
  - **Key Function:** `detects_objective_minmax(model_ir)` traces from objective through dependency chain
  - **Algorithm:** Worklist-based graph traversal with cycle detection, handles arbitrary-depth chains
  - **Test Coverage:** Direct min/max, 1-hop chains, 2-hop chains, nested min/max, negative cases
  - **Limitation:** Indexed objectives not yet supported (deferred - no current use cases)
  - **Performance:** O(V+E) graph traversal, <1ms for typical models
- Unknown 1.4 â€“ KKT assembly adjustments (âœ… COMPLETE) â†’ resolved during Day 1 research.
  - **Summary:** KKT assembly architecture already correct - no algorithmic changes needed
  - **Key Finding:** Current design is Jacobian-driven and automatically includes ALL equality constraints
  - **Architecture:** Partition â†’ Multipliers â†’ Stationarity separation works for auxiliary constraints
  - **Scaffolding:** Comprehensive TODO comments and logging framework already in place
  - **Day 2 Work:** Just add reformulation call to pipeline and enable debug logging
  - **Risk:** Low - architecture validated, scaffolding ready, test cases prepared
  - **Location:** `src/kkt/assemble.py` (lines 115-261), `src/cli.py` (pipeline integration)

---

### Day 2 â€“ Min/Max Bug Fix: Implementation & Testing

**Priority:** 1â€ƒ**Effort:** 8â€¯hâ€ƒ**Dependencies:** Dayâ€¯1 design
**Goals:** Finish implementation, validate with PATH, clean up tests.

- **Taskâ€¯2.1 â€“ Finalize Assembly** (3â€¯h)
  **Unknown:** 1.4 (âœ…)
  **Implementation Notes:** Research confirms KKT assembly architecture is ALREADY CORRECT. No algorithmic changes needed. Implementation simplified to:
  - Add `reformulate_model()` call in the pipeline after `normalize_model()` and before `compute_derivatives()`.
  - Enable debug logging in `assemble.py` to verify auxiliary constraints.
  - Verify reformulation creates constraints with correct Rel types.
  Scaffolding at lines 115-261 in `src/kkt/assemble.py` provides comprehensive TODO comments and logging framework.
  Complete multiplier integration, ensure indexed equations handled, add inline docs.

- **Taskâ€¯2.2 â€“ Debug Research Cases** (2â€¯h)
  Iterate on failing tests until generated MCPs are correct.

- **Taskâ€¯2.3 â€“ PATH Validation Smoke** (2â€¯h)
  **Unknown:** 1.5 (âœ… COMPLETE)
  Run all five min/max MCPs through PATH, experiment with options if convergence issues surface.
  **Implementation Notes from Research:**
  - Start with default PATH options (convergence_tolerance 1e-6, crash_method pnewton)
  - Default options should work for most reformulated min/max MCPs
  - If convergence fails, try "difficult model" configuration (see Unknown 1.5 findings)
  - If still failing, try "failing model" configuration with looser tolerance and no crash
  - Document which test cases (if any) require non-default options and why
  - PATH's stabilization scheme handles reformulated problems well (low risk)

- **Taskâ€¯2.4 â€“ Remove xfail** (0.5â€¯h)
  Drop xfail markers, annotate fixes in tests.

- **Taskâ€¯2.5 â€“ Regression Sweep** (0.5â€¯h)
  Run full pytest suite, address any fallout.

**Deliverables:** finalized assembly, green min/max tests, PATH validation results, tidy test suite.
**Acceptance:** five cases pass + PATH solves, full suite green, coverage â‰¥85â€¯%, mypy/ruff clean.
**Risks:** PATH non-convergence (use Unknownâ€¯1.5 mitigation), regression outside min/max (full suite).

**Follow-On Research Items**
- Unknownâ€¯1.5 â€“ PATH option tuning (âœ… COMPLETE) â†’ resolved November 7, 2025.
  - **Summary:** Comprehensive research completed on PATH solver options for MCP problems
  - **Key Finding:** Default PATH options (`convergence_tolerance 1e-6`, `crash_method pnewton`) are appropriate for min/max reformulated MCPs
  - **Recommendations:** Three configuration templates provided (standard/difficult/failing cases)
  - **Critical Options Identified:**
    - `convergence_tolerance` (default 1e-6): Adjust to 1e-4 for difficult models or 1e-8 for high precision
    - `major_iteration_limit` (default 500): Increase to 1000-2000 for complex reformulations
    - `crash_method` (default pnewton): Try `none` if default convergence fails
    - `proximal_perturbation` (default 0): Enable 1e-4 to 1e-2 for singular matrix issues
  - **Implementation Notes:**
    - Day 2 Task 2.3: Test with default options first; only tune if convergence fails
    - Day 3 Task 3.3: Create `docs/PATH_SOLVER.md` with option reference and troubleshooting guide
    - Include three configuration templates and decision tree for option tuning
  - **Risk Assessment:** Low - PATH's stabilization scheme handles reformulated problems well
  - **Documentation Required:** PATH_SOLVER.md with options reference, troubleshooting flowchart, and example configurations

---

### Day 3 â€“ PATH Validation & Checkpointâ€¯1 âœ… COMPLETE

**Priority:** 2â€ƒ**Effort:** 7â€¯h + 1â€¯h checkpointâ€ƒ**Dependencies:** Dayâ€¯2
**Goals:** Run complete PATH suite, document solver usage, complete Checkpointâ€¯1.

- **Taskâ€¯3.1 â€“ Execute Validation Suite** (2â€¯h)
  Run PATH validation tests; capture status/residuals.

- **Taskâ€¯3.2 â€“ Investigate Failures** (2â€¯h)
  **Unknown:** 2.1 (ğŸ”)
  Analyse Model Statusâ€¯5 cases, differentiate expected model infeasibility vs bugs.

- **Taskâ€¯3.3 â€“ Document PATH Usage** (2â€¯h)
  **Unknowns:** 2.2 (ğŸ”), 2.3 (ğŸ”)
  Author `docs/PATH_SOLVER.md`, update user guide with solver options and interpretation.
  **Implementation Notes from Unknown 1.5 Research:**
  - Include comprehensive PATH options reference (see Unknown 1.5 findings for complete list)
  - Document three configuration templates:
    1. Standard: Default options for most cases (convergence_tolerance 1e-6, crash_method pnewton)
    2. Difficult: For complex reformulations (major_iteration_limit 1000, proximal_perturbation 1e-4)
    3. Failing: For problematic models (looser tolerance 1e-4, crash_method none)
  - Add troubleshooting decision tree: convergence failure â†’ looser tolerance â†’ no crash â†’ proximal perturbation
  - Document how to create and use PATH option files (path.opt syntax)
  - Include table of key options with defaults and recommendations
  - Explain how to interpret PATH output (Model Status codes, residuals, iteration counts)
  - Note that default options work well for min/max reformulated MCPs (validated by research)

- **Taskâ€¯3.4 â€“ Test Suite Hygiene** (1â€¯h)
  Adjust skip/xfail expectations, embed solver option defaults.

- **Checkpointâ€¯1** (1â€¯h)
  Review feature completeness, unknown status, coverage, lint/test health; decide GO/NO-GO for Dayâ€¯4+.

**Deliverables:** PATH results log, documentation updates, stable validation suite, checkpoint report.
**Acceptance:** â‰¥90â€¯% PATH success, failures documented, PATH guide published, checkpoint GO with no blockers.

**âœ… COMPLETED (November 7, 2025):**
- âœ… PATH success rate: 100% (4/4 non-xfail tests - exceeds 90% target)
- âœ… Failures documented: 1 expected xfail documented in test and validation report
- âœ… PATH guide published: docs/PATH_SOLVER.md (450+ lines comprehensive guide)
- âœ… Checkpoint 1: GO decision - no blockers for Day 4+
- âœ… All Day 3 tasks complete (3.1, 3.2, 3.3, 3.4)
- âœ… Quality gates: typecheck âœ“, lint âœ“, format âœ“, tests âœ“

**Risks:** Solver option gaps (document + mitigation), new unknowns (capture in follow-on list).

**Follow-On Research Items**
- Unknownâ€¯2.1 â€“ Model Statusâ€¯5 diagnostics (âœ… COMPLETE) â†’ Dayâ€¯3.
- Unknownâ€¯2.2 â€“ Document PATH options (âœ… COMPLETE) â†’ Dayâ€¯3 completed Nov 7, 2025
  - **Note:** Comprehensive PATH_SOLVER.md created with options reference, templates, and troubleshooting
  - Unknown 1.5 research findings integrated
  - USER_GUIDE.md updated with PATH solver section
- Unknownâ€¯2.3 â€“ PATH solution quality guidance (âœ… COMPLETE) â†’ Included in PATH_SOLVER.md (Model Status interpretation, residuals, metrics)
- Unknownâ€¯2.4 â€“ PATH in CI/CD (ğŸ”, deferred to Sprintâ€¯6).

---

### Day 4 â€“ Production Hardening: Error Recovery

**Priority:** 3.1â€ƒ**Effort:** 8â€¯hâ€ƒ**Dependencies:** None
**Goals:** Harden numerical handling, validation, and messaging.

- **Taskâ€¯4.1 â€“ Numerical Guardrails** (2â€¯h)
  **Unknown:** 3.4 (ğŸ”)
  Detect NaN/Inf post-operation, surface contextual `NumericalError`.

- **Taskâ€¯4.2 â€“ Model Validation Pass** (2â€¯h)
  **Unknown:** 3.5 (ğŸ”)
  Add pre-assembly validation for undefined symbols, circular deps, type mismatches, missing objectives.

- **Taskâ€¯4.3 â€“ Message Improvements** (2â€¯h)
  Enhance errors with location, context, remediation pointers.

- **Taskâ€¯4.4 â€“ Recovery Tests** (2â€¯h)
  Build â‰¥20 integration tests covering failure scenarios and verifying guidance.

**Deliverables:** NaN/Inf hooks, validation module, improved error catalogue, recovery test suite.
**Acceptance:** Validation catches targeted mistakes, error messages actionable, â‰¥20 new tests passing, coverage â‰¥85â€¯%.
**Risks:** False positives from validation (allow opt-out flag), perf hit (profile, optimise).

**Follow-On Research Items**
- Unknownâ€¯3.4 â€“ Numerical handling approach (âœ… - COMPLETE) â†’ Dayâ€¯4.
- Unknownâ€¯3.5 â€“ Validation design (âœ… - COMPLETE) â†’ Dayâ€¯4.

---

### Day 5 â€“ Production Hardening: Large Models & Memory

**Priority:** 3.2 & 3.3 **Effort:** 8 h **Dependencies:** Large-model fixtures from prep
**Status:** âœ… COMPLETE (Nov 7, 2025)
**Goals:** Benchmark large-model throughput, profile time/memory, codify targets.

- **Task 5.1 â€“ Fixture Runs** (2 h) âœ… COMPLETE
  Execute 250/500/1000 variable models, record timings and correctness.
  **Results:** 250 vars (4.18s), 500 vars (10.71s), 1K vars (42.58s) - all within targets

- **Task 5.2 â€“ Time Profiling** (2 h) âœ… COMPLETE
  Break down phase runtimes with cProfile/line-profiler.
  **Results:** Jacobian 80%, Parsing 15%, Validation 5% - no optimization needed

- **Task 5.3 â€“ Memory Profiling** (2 h) âœ… COMPLETE
  **Unknown:** 3.3 (âœ… COMPLETE)
  Measure peak usage, apply sparse structures or generators if >500 MB.
  **Results:** 59.56 MB peak for 500 vars (88% under 500 MB target) - excellent

- **Task 5.4 â€“ Benchmark Suite** (2 h) âœ… COMPLETE
  Add `tests/benchmarks/test_large_models.py`, wire optional slow CI targets.
  **Results:** All benchmarks pass, infrastructure verified

**Deliverables:** âœ… Timing + memory reports (docs/performance/DAY5_PERFORMANCE_REPORT.md), benchmark tests passing, targets documented.
**Acceptance:** âœ… Fixtures within targets, âœ… memory â‰¤500 MB (59.56 MB), âœ… benchmarks pass (937 tests), âœ… no regressions vs Sprint 4.
**Risks:** âœ… No parser/AD regressions found, âœ… no memory spikes detected.

**Follow-On Research Items**
- Unknown 3.3 â€“ Memory optimization tactics (âœ… COMPLETE) â†’ Day 5 completed Nov 7, 2025.
  - **Summary:** Current memory usage excellent (59.56 MB for 500 vars, 88% under 500 MB target)
  - **Finding:** No optimization needed - dict-based sparse storage is efficient
  - **Recommendation:** Continue with current architecture, monitor for >2K variable models
  - **Documentation:** See docs/performance/DAY5_PERFORMANCE_REPORT.md for complete analysis

---

### Day 6 â€“ Production Hardening: Edge Cases & Checkpointâ€¯2

**Priority:** 3â€ƒ**Effort:** 7â€¯h + 1â€¯h checkpointâ€ƒ**Dependencies:** Daysâ€¯4â€“5
**Goals:** Cover critical edge cases, document limits, hold Checkpointâ€¯2.

**Status:** âœ… COMPLETE (Nov 7, 2025)

- **Taskâ€¯6.1 â€“ Edge Case Suite** (3â€¯h)
  **Unknown:** 3.2 (ğŸ”)
  Implement â‰¥20 cases across bounds, degeneracy, zero Jacobians, circular references, empty sets.

- **Taskâ€¯6.2 â€“ Boundary Testing** (2â€¯h)
  Stress test dimensional limits, nest depth, identifier length; record constraints.

- **Taskâ€¯6.3 â€“ Message Validation** (1â€¯h)
  Review error clarity from new cases; patch gaps.

- **Taskâ€¯6.4 â€“ Limitations Doc** (1â€¯h)
  Author `docs/LIMITATIONS.md`, link from README and user guide.

- **Checkpointâ€¯2** (1â€¯h)
  Validate progress vs plan, quality metrics, scope adjustments, readiness for packaging.

**Deliverables:** Edge-case tests, boundary write-up, LIMITATIONS doc, checkpoint report.
**Acceptance:** â‰¥20 tests pass/fail gracefully, documented limits published, checkpoint GO for Dayâ€¯7.
**Risks:** Newly uncovered critical issues (surface early, feed into Dayâ€¯10 buffer).

**Follow-On Research Items**
- Unknownâ€¯3.2 â€“ Edge-case catalogue (ğŸ”) â†’ Dayâ€¯6.

---

### Day 7 â€“ PyPI Packaging: Configuration & Build

**Priority:** 4â€ƒ**Effort:** 8â€¯hâ€ƒ**Dependencies:** None
**Goals:** Select build backend, configure packaging metadata, validate local installs.

- **Taskâ€¯7.1 â€“ Build System Decision** (1â€¯h)
  **Unknown:** 4.1 (ğŸ”)
  Compare setuptools/hatch/flit; adopt hatch for modern workflow.

- **Task 7.2 â€“ `pyproject.toml` Setup** (30 min)
  **Unknown:** 4.2 (âœ… COMPLETE - research done Nov 8)
  **Implementation:** Update `requires-python = ">=3.11"` (was >=3.12), upgrade to `"Development Status :: 4 - Beta"`, add 11 new classifiers (Python 3.11/3.13, Developers audience, Code Generators topic, OS Independent, Console, Natural Language, Typing). Update license to SPDX format `license = "MIT"`. Already have: metadata, dependencies, optional extras, CLI entry point.
  **Why 30min:** Most metadata already complete. Just need classifier updates and Python version change. See KNOWN_UNKNOWNS.md Unknown 4.2 for full classifier list.

- **Taskâ€¯7.3 â€“ CLI Entry Point** (1â€¯h)
  Configure console script in `pyproject.toml`; verify CLI usage text.

- **Taskâ€¯7.4 â€“ Wheel Build** (1â€¯h)
  Produce wheel via `python -m build`, inspect distribution.

- **Taskâ€¯7.5 â€“ Local Install QA** (2â€¯h)
  Smoke test install/uninstall in fresh venv, run CLI on sample models.

- **Taskâ€¯7.6 â€“ Multi-Platform Check** (1â€¯h)
  **Unknown:** 4.3 (ğŸ”)
  Exercise tox across Python 3.11â€“3.12 on macOS; note issues for Dayâ€¯8 CI matrix.

**Deliverables:** pyproject metadata, built wheel, install report, multi-platform notes.
**Acceptance:** Wheel build passes, CLI operational post-install, dependencies resolved, python matrix smoke green.
**Risks:** Missing package data (validate wheel contents), CLI entry misconfigurations (smoke test).

**Follow-On Research Items**
- Unknown 4.1 â€“ Build backend choice (âœ… COMPLETE) â†’ **Decision: Keep setuptools** (Nov 7, 2025). Pure Python, setuptools working, 79% adoption, zero risk. Fix: SPDX license. Saves 2h Day 7.
- Unknown 4.2 â€“ PyPI metadata checklist (âœ… COMPLETE) â†’ **Decision: Support Python 3.11+, upgrade to Beta status, add 11 classifiers** (Nov 8, 2025). NumPy requires 3.11+. Add Developer audience, Code Generator topic, OS Independent. Improves discoverability 30-40%. Task 7.2: 30min.
- Unknownâ€¯4.3 â€“ Multi-platform strategy (ğŸ”) â†’ Dayâ€¯7.

---

### Day 8 â€“ PyPI Release Automation & Checkpointâ€¯3

**Priority:** 4â€ƒ**Effort:** 7â€¯h + 1â€¯h checkpointâ€ƒ**Dependencies:** Dayâ€¯7
**Goals:** Automate versioning/changelog, configure publish workflow, push to TestPyPI, update docs/CHANGELOG, run Checkpointâ€¯3.

- **Taskâ€¯8.1 â€“ Version Strategy** (0.5â€¯h)
  **Unknown:** 4.4 (ğŸ”)
  Document semantic version path (0.4.0 launch â†’ 1.0.0 readiness).

- **Taskâ€¯8.2 â€“ Version Bump Script** (1.5â€¯h)
  Create `scripts/bump_version.py`, integrate with workflow.

- **Taskâ€¯8.3 â€“ Changelog Generator** (1.5â€¯h)
  Build `scripts/generate_changelog.py` (Keep a Changelog format) and automation hook.

- **Taskâ€¯8.4 â€“ GitHub Actions Workflow** (1.5â€¯h)
  Compose `.github/workflows/publish-pypi.yml` with build/test/publish steps (dry-run on branch).

- **Taskâ€¯8.5 â€“ TestPyPI Publish** (0.5â€¯h)
  Upload artefacts via `twine`, verify listing.

- **Taskâ€¯8.6 â€“ TestPyPI Install QA** (0.5â€¯h)
  Install from TestPyPI in clean venv, run CLI.

- **Taskâ€¯8.7 â€“ Release Docs** (0.5â€¯h)
  Draft/refresh `RELEASING.md` with automated steps and manual checklist.

- **Taskâ€¯8.8 â€“ README Update** (0.5â€¯h)
  Document `pip install`, add PyPI badge, verify quick-start.

- **Taskâ€¯8.9 â€“ CHANGELOG Update** (0.5â€¯h)
  Record Sprintâ€¯5 highlights using automation output; manually sanity check.

- **Checkpointâ€¯3** (1â€¯h)
  Confirm Priorityâ€¯1-4 completion, release readiness, doc readiness; GO/NO-GO for Dayâ€¯9 documentation.

**Deliverables:** Version/changelog scripts, CI workflow, TestPyPI release, updated README & CHANGELOG, checkpoint report.
**Acceptance:** Automation scripts tested, workflow passes, TestPyPI install validated, docs updated, checkpoint GO.
**Risks:** Secret misconfig (dry-run, manual fallback), automation bugs (local tests before CI).

**Follow-On Research Items**
- Unknownâ€¯4.4 â€“ Versioning plan (ğŸ”) â†’ Dayâ€¯8.

---

### Day 9 â€“ Documentation Push (Tutorial, FAQ, Troubleshooting, API Site)

**Priority:** 5â€ƒ**Effort:** 8â€¯hâ€ƒ**Dependencies:** Daysâ€¯1â€“8 complete
**Goals:** Deliver complete end-user documentation, publish API reference.

- **Taskâ€¯9.1 â€“ Tutorial Outline** (1â€¯h)
  **Unknown:** 5.2 (ğŸ”)
  Finalise sections, assets, and examples.

- **Taskâ€¯9.2 â€“ Tutorial Authoring** (3â€¯h)
  Produce `docs/TUTORIAL.md` with runnable samples, screenshots/diagrams, cross-links.

- **Taskâ€¯9.3 â€“ FAQ Build** (1.5â€¯h)
  Source â‰¥20 real questions from testing/edges/retro, structure by theme, provide answers + links.

- **Taskâ€¯9.4 â€“ Troubleshooting Upgrade** (0.5â€¯h)
  **Unknown:** 5.3 (ğŸ”)
  Rework `docs/TROUBLESHOOTING.md` with Problem â†’ Diagnosis â†’ Solution sections and error snippets.

- **Taskâ€¯9.5 â€“ API Documentation Site** (2â€¯h)
  **Unknowns:** 5.1 (âœ…), 5.4 (ğŸ”)
  Configure Sphinx (autodoc/type hints), generate HTML, prep GitHub Pages/ReadTheDocs deployment.

**Deliverables:** Tutorial, FAQ, enhanced troubleshooting guide, Sphinx site, deployment steps.
**Acceptance:** Examples verified, â‰¥20 FAQ entries, Sphinx build succeeds, docs cross-linked, no broken links.
**Risks:** Documentation scope overrun (use Dayâ€¯10 buffer), Sphinx dependencies (lock requirements early).

**Follow-On Research Items**
- Unknownâ€¯5.1 â€“ Tooling decision (âœ… resolved: Sphinx).
- Unknownâ€¯5.2 â€“ Tutorial scope (ğŸ”) â†’ Dayâ€¯9.
- Unknownâ€¯5.3 â€“ Troubleshooting depth (ğŸ”) â†’ Dayâ€¯9.
- Unknownâ€¯5.4 â€“ API detail level (ğŸ”) â†’ Dayâ€¯9.

---

### Day 10 â€“ Polish & Buffer

**Priority:** Bufferâ€ƒ**Effort:** 8â€¯hâ€ƒ**Dependencies:** Daysâ€¯1â€“9
**Goals:** Close outstanding work, perform quality sweep, prep retrospective.

- **Taskâ€¯10.1 â€“ Backlog Burn-down** (4â€¯h)
  Finish any open acceptance criteria (priority: critical â†’ high â†’ medium â†’ low).

- **Taskâ€¯10.2 â€“ Final QA Pass** (2â€¯h)
  Run full tests, coverage, mypy, ruff, black; verify docs links, package install sanity.

- **Taskâ€¯10.3 â€“ Retrospective Prep** (1â€¯h)
  Collect metrics (tests, coverage, performance, release stats), draft talking points/action items.

- **Taskâ€¯10.4 â€“ Deliverables Checklist** (1â€¯h)
  Ensure all Sprintâ€¯5 outputs complete, sign off for demo/release.

**Deliverables:** Cleared backlog, QA evidence, retro notes, completion checklist.
**Acceptance:** Critical/high items complete, all tests pass, coverage â‰¥85â€¯%, docs + release assets verified, retro packet ready.
**Risks:** Late surprises (buffer absorbs), remaining low-priority tasks may slip (document deferrals).

**Follow-On Research Items**
- Critical/high unknowns resolved Daysâ€¯1â€“9; any new low-priority discoveries are flagged for Sprintâ€¯6 planning.

---

## Risk Management

| Risk | Prob. | Impact | Mitigation | Contingency |
| --- | --- | --- | --- | --- |
| Min/max fix complexity | Medium | High | Dedicated Daysâ€¯1â€“2, research complete, checkpoints | Scope to common cases, defer edge scenarios |
| PATH licensing/access | Low | High | Dependencies verified in prep, manual path if CI unavailable | Run manual solver sessions, document limits |
| Release automation defects | Medium | Medium | Local script tests, dry-run workflow, manual checklist | Fall back to manual release process |
| Performance misses targets | Low | Medium | Benchmarks + profiling Dayâ€¯5, documented baselines | Publish current metrics, schedule optimisation |
| Documentation overrun | Medium | Low | Full Dayâ€¯9 allocation, Dayâ€¯10 buffer | Ship reduced docs, refine next sprint |
| Edge cases unveil blockers | Low | High | Systematic testing Dayâ€¯6, early checkpoint | Document + schedule remediation |
| Sphinx build instability | Low | Low | Lock dependencies, early build dry run | Defer API site to Sprintâ€¯6 if required |

---

## Dependencies

```
Day 1 â†’ Day 2 â†’ Day 3 â†’ (Checkpt 1 GO)
       â†˜ï¸ Day 4 â†’ Day 5 â†’ Day 6 â†’ (Checkpt 2 GO)
                           â†˜ï¸ Day 7 â†’ Day 8 â†’ (Checkpt 3 GO) â†’ Day 9 â†’ Day 10
```

**External:**
- GAMS/PATH licenses (validated during prep) for Daysâ€¯2â€“3 PATH work.
- Large-model fixtures from prep Taskâ€¯8 feed Dayâ€¯5 benchmarks.
- PyPI/TestPyPI credentials for Dayâ€¯8 automation.
- Documentation tooling (Sphinx, MkDocs legacy docs) configured through prep tasks.

---

## Sprint Success Definition

**Minimum (B):** Min/max fix, PATH validation, large-model benchmarks, PyPI build, tutorial, â‰¥1000 tests, â‰¥80â€¯% coverage.
**Target (A):** Minimum plus error recovery suite, memory tuning, edge-case coverage, TestPyPI publish, FAQ, release automation, â‰¥85â€¯% coverage, checkpoints passed.
**Stretch (A+):** Target plus production PyPI release, API site deployed, performance exceeds targets, zero deferred critical items, Sprint complete by Dayâ€¯9.

---

## Known Unknowns Tracking

Active unknowns, ownership, and target resolution day:

- **Category 1 (Min/Max):** 1.2, 1.4, 1.5 â†’ Daysâ€¯1â€“2.
- **Category 2 (PATH):** 2.1, 2.2, 2.3 â†’ Dayâ€¯3; 2.4 deferred to Sprintâ€¯6.
- **Category 3 (Hardening):** 3.2 â†’ Dayâ€¯6; 3.3 â†’ Dayâ€¯5; 3.4â€“3.5 â†’ Dayâ€¯4.
- **Category 4 (Packaging):** 4.1â€“4.3 â†’ Dayâ€¯7; 4.4 â†’ Dayâ€¯8.
- **Category 5 (Docs):** 5.2â€“5.4 â†’ Dayâ€¯9 (5.1 resolved: Sphinx).
- Any new discoveries are logged during checkpoints and evaluated for mitigation or deferral.

---

## Checkpoint Cadence

- **Checkpointâ€¯0 (Prep, complete):** Dependencies + retrospective alignment.
- **Checkpointâ€¯1 (Dayâ€¯3):** Validate Priorityâ€¯1â€“2 execution, unblock hardening.
- **Checkpointâ€¯2 (Dayâ€¯6):** Confirm production hardening outcomes before packaging.
- **Checkpointâ€¯3 (Dayâ€¯8):** Release readiness prior to documentation push.

Each checkpoint uses templates in `docs/process/CHECKPOINT_TEMPLATES.md` and explicitly records GO/NO-GO decisions plus remediation plans if needed.

---

## Definition of Done

Sprint 5 concludes when:
- All Success Metrics targets are met or deviations are documented and approved.
- Release artefacts (package, automation, docs) are published and verified.
- CHANGELOG.md reflects Sprintâ€¯5 changes.
- Retro inputs compiled, and outstanding items are scheduled or deferred with rationale.

Upon completion, update CHANGELOG.md and tag the release per the automated workflow.***
