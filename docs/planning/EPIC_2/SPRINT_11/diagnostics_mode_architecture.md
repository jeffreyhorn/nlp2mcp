# Diagnostics Mode Architecture

**Date:** 2025-11-26  
**Task:** Sprint 11 Prep Task 9 - Design Diagnostics Mode Architecture  
**Objective:** Design architecture for `--diagnostic` mode showing stage-by-stage stats, pipeline decisions, and simplification summaries

---

## Executive Summary

This document designs the architecture for Sprint 11's diagnostics mode (`--diagnostic` flag), providing visibility into the NLP‚ÜíMCP conversion pipeline. **Key decision:** Implement **two-tier verbosity** (summary + detailed) with **text table output** in Sprint 11, deferring JSON output and dashboard integration to Sprint 12.

**Critical Findings:**
- **Granularity:** Stage-level diagnostics (parse, semantic, simplification, IR generation, MCP generation) with per-pass breakdowns for simplification
- **Output Format:** Pretty-printed text tables for Sprint 11 (implementation: 4-5h), JSON output deferred to Sprint 12 (+2h)
- **Performance Overhead:** <2% overhead for stage-level timing, <5% for detailed simplification tracking
- **Verbosity Levels:** Default (summary only), `--diagnostic` (detailed), `--diagnostic --verbose` (debug)

**Sprint 11 Recommendation:** Implement text-based diagnostic output with stage timing, simplification breakdowns, and transformation summaries. Provides 90% of value with 40% less implementation effort than JSON + dashboard.

---

## Table of Contents

1. [Section 1: Diagnostic Output Structure](#section-1-diagnostic-output-structure)
2. [Section 2: Simplification Diagnostics](#section-2-simplification-diagnostics)
3. [Section 3: Performance Profiling](#section-3-performance-profiling)
4. [Section 4: Output Mechanism](#section-4-output-mechanism)
5. [Section 5: Implementation Roadmap](#section-5-implementation-roadmap)
6. [Appendix A: Example Diagnostic Outputs](#appendix-a-example-diagnostic-outputs)
7. [Appendix B: Comparison with Other Tools](#appendix-b-comparison-with-other-tools)

---

## Section 1: Diagnostic Output Structure

### 1.1 Pipeline Stages

**Conversion Pipeline (5 main stages):**

```
Input GAMS file
    ‚Üì
[Stage 1] Parsing              # GAMS ‚Üí AST
    ‚Üì
[Stage 2] Semantic Analysis    # AST ‚Üí Validated AST
    ‚Üì
[Stage 3] Simplification       # Expression simplification (8 sub-passes)
    ‚Üì
[Stage 4] IR Generation        # Validated AST ‚Üí IR
    ‚Üì
[Stage 5] MCP Generation       # IR ‚Üí MCP GAMS
    ‚Üì
Output MCP GAMS file
```

**Stage Definitions:**

| Stage | Input | Output | Key Metrics |
|-------|-------|--------|-------------|
| **1. Parsing** | GAMS text | AST | Lines parsed, parse errors, AST node count |
| **2. Semantic Analysis** | AST | Validated AST | Symbols resolved, type errors, scope depth |
| **3. Simplification** | Validated AST | Simplified AST | Term count reduction, transformation count, iterations |
| **4. IR Generation** | Simplified AST | IR | Variables, parameters, equations, constraints |
| **5. MCP Generation** | IR | MCP GAMS | Complementarity pairs, MCP vars, MCP equations |

### 1.2 Stage-Level Metrics

**Per-Stage Metrics to Track:**

**1. Performance Metrics:**
- **Time:** Wall-clock time for stage (milliseconds)
- **Memory:** Peak memory delta for stage (MB)
- **Percentage:** % of total conversion time

**2. Size Metrics:**
- **Input size:** AST node count, expression count, line count
- **Output size:** AST node count after transformations
- **Delta:** Absolute and relative change

**3. Transformation Metrics:**
- **Transformations applied:** Count of modifications
- **Transformations skipped:** Count of attempted but rejected changes
- **Reason summary:** Why transformations were skipped (size budget, no benefit, etc.)

**4. Quality Metrics:**
- **Errors:** Count of errors detected in stage
- **Warnings:** Count of warnings emitted
- **Success rate:** % of elements successfully processed

### 1.3 Verbosity Levels

**Three Verbosity Levels:**

#### Level 0: Default (No --diagnostic flag)
```
Converting rbrock.gms...
‚úì Conversion complete (45.2ms)
Output: rbrock_mcp.gms
```

**Output:** Minimal (just success/failure + total time)

#### Level 1: Summary (--diagnostic)
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Conversion Pipeline: rbrock.gms                                 ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Stage              ‚îÇ Time (ms) ‚îÇ % Total ‚îÇ Size In ‚Üí Out       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 1. Parsing         ‚îÇ     12.4  ‚îÇ   27.4% ‚îÇ 48 lines ‚Üí 127 AST  ‚îÇ
‚îÇ 2. Semantic        ‚îÇ      3.8  ‚îÇ    8.4% ‚îÇ 127 AST ‚Üí 127 AST   ‚îÇ
‚îÇ 3. Simplification  ‚îÇ     18.7  ‚îÇ   41.4% ‚îÇ 89 terms ‚Üí 52 terms ‚îÇ
‚îÇ 4. IR Generation   ‚îÇ      6.2  ‚îÇ   13.7% ‚îÇ 2 vars, 1 eq        ‚îÇ
‚îÇ 5. MCP Generation  ‚îÇ      4.1  ‚îÇ    9.1% ‚îÇ 2 vars, 1 eq        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ TOTAL              ‚îÇ     45.2  ‚îÇ  100.0% ‚îÇ                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Simplification Summary:
  ‚Ä¢ Term count reduction: 89 ‚Üí 52 (41.6% reduction)
  ‚Ä¢ Transformations applied: 23
  ‚Ä¢ Fixpoint iterations: 3

Output: rbrock_mcp.gms
```

**Output:** Stage timing, size changes, simplification summary

#### Level 2: Detailed (--diagnostic --verbose)
```
[Same as Level 1, plus:]

Simplification Breakdown (3 iterations):

Iteration 1:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Pass                          ‚îÇ Applied ‚îÇ Terms Before ‚Üí After ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 1. Basic Simplification       ‚îÇ    12   ‚îÇ      89 ‚Üí 77         ‚îÇ
‚îÇ 2. Like-Term Combination      ‚îÇ     5   ‚îÇ      77 ‚Üí 72         ‚îÇ
‚îÇ 3. Associativity for Constants‚îÇ     3   ‚îÇ      72 ‚Üí 69         ‚îÇ
‚îÇ 4. Fraction Combining         ‚îÇ     0   ‚îÇ      69 ‚Üí 69         ‚îÇ
‚îÇ 5. Factoring                  ‚îÇ     7   ‚îÇ      69 ‚Üí 62         ‚îÇ
‚îÇ 6. Division Simplification    ‚îÇ     2   ‚îÇ      62 ‚Üí 60         ‚îÇ
‚îÇ 7. Multi-Term Factoring       ‚îÇ     0   ‚îÇ      60 ‚Üí 60         ‚îÇ
‚îÇ 8. CSE                        ‚îÇ     0   ‚îÇ      60 ‚Üí 60         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Iteration 2:
  [Similar breakdown, fewer transformations]

Iteration 3:
  No changes ‚Üí converged

Transformation Details:
  ‚Ä¢ Basic simplification: 12 (constant folding: 8, identity: 4)
  ‚Ä¢ Like-term combination: 5 (addition: 3, multiplication: 2)
  ‚Ä¢ Associativity: 3 (all constants consolidated)
  ‚Ä¢ Factoring: 7 (common factor extraction: 7)
  ‚Ä¢ Division: 2 (constant cancellation: 2)

Skipped Transformations:
  ‚Ä¢ Fraction combining: 0 candidates (no common denominators)
  ‚Ä¢ Multi-term factoring: 0 candidates (no 2√ó2 patterns)
  ‚Ä¢ CSE: 0 candidates (min reuse threshold not met)
```

**Output:** Per-pass breakdowns, transformation details, skip reasons

### 1.4 Diagnostic Output Schema

**Structured Data Model (for implementation):**

```python
@dataclass
class StageStats:
    """Statistics for a single pipeline stage."""
    name: str                    # e.g., "Parsing"
    time_ms: float               # Wall-clock time
    memory_mb: float             # Peak memory delta
    input_size: int              # AST nodes / line count
    output_size: int             # AST nodes after stage
    errors: int                  # Error count
    warnings: int                # Warning count
    metadata: dict[str, Any]     # Stage-specific metrics

@dataclass
class SimplificationPassStats:
    """Statistics for a single simplification pass."""
    pass_name: str               # e.g., "Basic Simplification"
    transformations_applied: int # Count of changes
    transformations_skipped: int # Count of rejected changes
    terms_before: int            # Term count before pass
    terms_after: int             # Term count after pass
    time_ms: float               # Pass execution time
    skip_reasons: dict[str, int] # Reason ‚Üí count mapping

@dataclass
class DiagnosticReport:
    """Complete diagnostic report for a conversion."""
    model_name: str
    total_time_ms: float
    total_memory_mb: float
    stages: list[StageStats]
    simplification_iterations: list[list[SimplificationPassStats]]
    success: bool
    output_file: str | None
```

---

## Section 2: Simplification Diagnostics

### 2.1 Simplification Pass Breakdown

**8-Pass Simplification Pipeline (from Task 3):**

1. **Basic Simplification** (existing)
   - Constant folding
   - Identity elimination (x+0, x*1)
   - Zero elimination (x*0)

2. **Like-Term Combination** (existing)
   - Addition: 2x + 3x ‚Üí 5x
   - Multiplication: x¬≤ * x¬≥ ‚Üí x‚Åµ

3. **Associativity for Constants** (NEW)
   - (2 * x) * 3 ‚Üí 6 * x
   - x + (y + 5) ‚Üí x + y + 5

4. **Fraction Combining** (NEW)
   - x/a + y/a ‚Üí (x+y)/a

5. **Factoring** (NEW)
   - x*y + x*z ‚Üí x*(y+z)

6. **Division Simplification** (NEW)
   - (x/a)/b ‚Üí x/(a*b)

7. **Multi-Term Factoring** (NEW)
   - a*c + a*d + b*c + b*d ‚Üí (a+b)*(c+d)

8. **CSE** (NEW, optional)
   - œÜ(a,b) = sqrt(a¬≤+b¬≤); use œÜ twice ‚Üí temp = œÜ; reuse

### 2.2 Per-Pass Metrics

**Metrics to Track per Pass:**

```python
@dataclass
class TransformationMetrics:
    """Detailed metrics for a single transformation type."""
    type: str                      # e.g., "constant_folding"
    applied: int                   # Successful applications
    attempted: int                 # Total attempts
    skipped: int                   # Rejected applications
    skip_reasons: dict[str, int]   # Reason ‚Üí count
    term_reduction: int            # Net term count change
    time_ms: float                 # Time spent on this transform
```

**Example Metrics for "Basic Simplification" Pass:**

```
Basic Simplification (Pass 1):
  ‚Ä¢ Constant folding: 8 applied (2+3 ‚Üí 5, 4*5 ‚Üí 20, ...)
  ‚Ä¢ Identity elimination: 4 applied (x+0 ‚Üí x, x*1 ‚Üí x, ...)
  ‚Ä¢ Zero elimination: 0 applied (no x*0 patterns)
  ‚Ä¢ Total transformations: 12
  ‚Ä¢ Term reduction: 89 ‚Üí 77 (13.5%)
  ‚Ä¢ Time: 3.2ms
```

### 2.3 Transformation Application Details

**Two Detail Levels:**

#### Summary (--diagnostic):
```
Simplification Summary:
  ‚Ä¢ Transformations applied: 23
  ‚Ä¢ Term count: 89 ‚Üí 52 (41.6% reduction)
  ‚Ä¢ Fixpoint iterations: 3
  ‚Ä¢ Time: 18.7ms
```

#### Detailed (--diagnostic --verbose):
```
Simplification Details:

Iteration 1 (29 transformations, 89 ‚Üí 60 terms):
  [1] Basic Simplification:
      - Constant folding: 8 (e.g., 2+3 ‚Üí 5 in expr_42)
      - Identity elim: 4 (e.g., x*1 ‚Üí x in expr_17)
      - Term count: 89 ‚Üí 77
  
  [2] Like-Term Combination:
      - Addition: 3 (e.g., 2*x + 3*x ‚Üí 5*x in expr_9)
      - Multiplication: 2 (e.g., x¬≤ * x ‚Üí x¬≥ in expr_24)
      - Term count: 77 ‚Üí 72
  
  [3] Associativity:
      - Constants consolidated: 3
      - Term count: 72 ‚Üí 69
  
  [4] Fraction Combining:
      - No candidates (0 common denominators found)
      - Term count: 69 ‚Üí 69
  
  [5] Factoring:
      - Common factor extraction: 7 (e.g., x*y + x*z ‚Üí x*(y+z))
      - Term count: 69 ‚Üí 62
  
  [6] Division Simplification:
      - Constant cancellation: 2
      - Term count: 62 ‚Üí 60
  
  [7] Multi-Term Factoring:
      - No candidates (0 2√ó2 patterns found)
      - Term count: 60 ‚Üí 60
  
  [8] CSE:
      - Skipped (reuse threshold not met)
      - Term count: 60 ‚Üí 60

Iteration 2 (4 transformations, 60 ‚Üí 52 terms):
  [Similar breakdown with fewer transformations]

Iteration 3:
  No transformations applied ‚Üí converged
```

### 2.4 Skip Reasons Taxonomy

**Why Transformations Are Skipped:**

| Reason | Description | Example |
|--------|-------------|---------|
| `no_candidates` | Pattern not found in AST | No common denominators for fraction combining |
| `size_budget_exceeded` | Transformation would violate 150% size limit | Distribution would create 200% larger expression |
| `no_benefit` | Transformation doesn't reduce terms | Factoring doesn't actually simplify |
| `already_optimal` | Expression already in simplest form | No constants to fold |
| `threshold_not_met` | Reuse count below minimum | CSE requires ‚â•3 reuses, only 2 found |
| `numerical_instability` | Transformation could cause precision loss | Dividing by very small constant |

**Example Skip Reason Reporting:**

```
Skipped Transformations:
  ‚Ä¢ Fraction combining: 12 attempts
      - no_candidates: 12 (no common denominators)
  ‚Ä¢ Multi-term factoring: 5 attempts
      - no_candidates: 3 (no 2√ó2 patterns)
      - no_benefit: 2 (factoring didn't reduce terms)
  ‚Ä¢ CSE: 8 attempts
      - threshold_not_met: 8 (reuse count < 3)
```

### 2.5 Heuristic Trigger Reporting

**Heuristics That Control Transformations:**

1. **Size Budget Heuristic:**
   - Limit: 150% of original size
   - Trigger: Check before each transformation
   - Report: "Size budget: 127/190 AST nodes (66.8% used)"

2. **Cancellation Detection:**
   - Trigger: Before distribution over division
   - Check: Will distribution enable variable cancellation?
   - Report: "Distribution applied (cancellation detected: x/x ‚Üí 1)"

3. **Reuse Threshold:**
   - Trigger: Before CSE
   - Check: Expression reused ‚â• threshold times?
   - Report: "CSE skipped (reuse=2 < threshold=3)"

**Example Heuristic Reporting:**

```
Heuristic Decisions:
  ‚Ä¢ Size budget: 127/190 AST nodes (66.8% used)
      - 3 transformations rejected (would exceed 150%)
  ‚Ä¢ Cancellation detection: 2 hits
      - Distribution applied at expr_17 (x cancellation)
      - Distribution applied at expr_42 (y cancellation)
  ‚Ä¢ Reuse threshold (CSE): 0 qualified
      - 8 expressions with reuse=2 (below threshold=3)
```

---

## Section 3: Performance Profiling

### 3.1 Time Measurement Approach

**Timing Strategy:**

```python
import time
from contextlib import contextmanager

@contextmanager
def timed_stage(stage_name: str, diagnostics: DiagnosticReport):
    """Context manager for timing a pipeline stage."""
    start_time = time.perf_counter()
    start_memory = get_memory_usage()
    
    try:
        yield
    finally:
        end_time = time.perf_counter()
        end_memory = get_memory_usage()
        
        diagnostics.add_stage(
            name=stage_name,
            time_ms=(end_time - start_time) * 1000,
            memory_mb=(end_memory - start_memory) / 1024 / 1024,
        )

# Usage in conversion pipeline
def convert_nlp_to_mcp(gams_file: str, diagnostic_mode: bool = False):
    diagnostics = DiagnosticReport() if diagnostic_mode else None
    
    with timed_stage("Parsing", diagnostics):
        ast = parse_gams_file(gams_file)
    
    with timed_stage("Semantic Analysis", diagnostics):
        validated_ast = analyze_semantics(ast)
    
    with timed_stage("Simplification", diagnostics):
        simplified_ast = simplify(validated_ast, diagnostics)
    
    # ... etc
    
    if diagnostics:
        print_diagnostic_report(diagnostics)
```

**Timing Granularity:**

- **Stage-level:** Always measured (minimal overhead)
- **Pass-level (simplification):** Measured in `--diagnostic` mode
- **Transformation-level:** Measured in `--diagnostic --verbose` mode

### 3.2 Memory Measurement Approach

**Memory Tracking:**

```python
import psutil
import os

def get_memory_usage() -> int:
    """Get current process memory usage in bytes."""
    process = psutil.Process(os.getpid())
    return process.memory_info().rss  # Resident Set Size

def measure_memory_delta(func):
    """Decorator to measure memory delta of a function."""
    def wrapper(*args, **kwargs):
        mem_before = get_memory_usage()
        result = func(*args, **kwargs)
        mem_after = get_memory_usage()
        mem_delta_mb = (mem_after - mem_before) / 1024 / 1024
        
        if hasattr(func, '__diagnostic_context__'):
            func.__diagnostic_context__.add_memory(mem_delta_mb)
        
        return result
    return wrapper
```

**Memory Metrics:**

- **Peak memory:** Maximum memory used during stage
- **Memory delta:** Net memory change (allocations - deallocations)
- **Memory efficiency:** Output size / memory used ratio

**Memory Reporting:**

```
Memory Usage:
  ‚Ä¢ Peak: 142.3 MB
  ‚Ä¢ Parsing: +12.4 MB
  ‚Ä¢ Semantic: +3.8 MB
  ‚Ä¢ Simplification: -5.2 MB (freed during optimization)
  ‚Ä¢ IR Generation: +8.7 MB
  ‚Ä¢ MCP Generation: +2.1 MB
```

### 3.3 Performance Overhead Assessment

**Overhead Targets:**

| Diagnostic Level | Target Overhead | Acceptable Range | Components |
|------------------|-----------------|------------------|------------|
| Default (no --diagnostic) | 0% | 0-0.5% | None (no profiling) |
| Summary (--diagnostic) | <2% | 1-3% | Stage timing, basic counters |
| Detailed (--diagnostic --verbose) | <5% | 3-7% | Pass timing, transformation tracking |

**Overhead Sources:**

1. **Timing calls:** `time.perf_counter()` is ~50ns per call
   - 10 stages √ó 2 calls = 1 Œºs (negligible)
   
2. **Memory calls:** `psutil.Process().memory_info()` is ~10 Œºs per call
   - 10 stages √ó 2 calls = 200 Œºs (negligible)
   
3. **Counter increments:** Simple integer increments
   - ~1000 transformations √ó 5ns = 5 Œºs (negligible)
   
4. **String formatting:** Main overhead source
   - Deferred until final report (not per-transformation)

**Overhead Measurement Strategy:**

```python
# Benchmark with and without diagnostics
def benchmark_overhead():
    models = ["rbrock.gms", "mhw4d.gms", "himmel16.gms"]
    
    for model in models:
        # Without diagnostics (10 runs)
        times_no_diag = []
        for _ in range(10):
            start = time.perf_counter()
            convert_nlp_to_mcp(model, diagnostic_mode=False)
            times_no_diag.append(time.perf_counter() - start)
        
        # With diagnostics (10 runs)
        times_with_diag = []
        for _ in range(10):
            start = time.perf_counter()
            convert_nlp_to_mcp(model, diagnostic_mode=True)
            times_with_diag.append(time.perf_counter() - start)
        
        # Calculate overhead
        avg_no_diag = sum(times_no_diag) / len(times_no_diag)
        avg_with_diag = sum(times_with_diag) / len(times_with_diag)
        overhead_pct = ((avg_with_diag - avg_no_diag) / avg_no_diag) * 100
        
        print(f"{model}: {overhead_pct:.2f}% overhead")
```

**Expected Overhead (estimates):**

| Model | Baseline (ms) | With --diagnostic (ms) | Overhead |
|-------|---------------|------------------------|----------|
| rbrock.gms | 45.2 | 45.8 | 1.3% |
| mhw4d.gms | 127.4 | 129.2 | 1.4% |
| himmel16.gms | 84.3 | 85.7 | 1.7% |

**Target: <2% overhead for --diagnostic mode ‚úÖ**

### 3.4 Profiling Granularity

**Three Profiling Levels:**

#### Level 0: No Profiling (default)
- Overhead: 0%
- Data collected: None
- Use case: Production conversions

#### Level 1: Stage-Level Profiling (--diagnostic)
- Overhead: ~1-2%
- Data collected:
  - 5 stage timings
  - 5 memory deltas
  - Basic counters (transformations applied, term count)
- Use case: Understanding which stage is slow

#### Level 2: Detailed Profiling (--diagnostic --verbose)
- Overhead: ~3-5%
- Data collected:
  - All Level 1 data
  - 8 simplification pass timings
  - Per-transformation counters
  - Skip reason tracking
  - Heuristic decision logging
- Use case: Debugging why simplification didn't reduce terms enough

---

## Section 4: Output Mechanism

### 4.1 Output Format Design

**Format Options Evaluated:**

| Format | Pros | Cons | Sprint 11 Decision |
|--------|------|------|-------------------|
| **Pretty Tables** | Human-readable, familiar, works in terminal | Not machine-parseable | ‚úÖ PRIMARY |
| **JSON** | Machine-parseable, structured, enables automation | Less readable for humans | ‚è∏Ô∏è DEFER to Sprint 12 |
| **YAML** | Human-readable AND parseable | Requires extra dependency | ‚ùå REJECT |
| **Structured Logs** | Integrates with logging infrastructure | Hard to get overview | ‚ùå REJECT |

**Decision: Pretty Tables for Sprint 11**

**Rationale:**
1. **Implementation time:** 4-5h for tables vs 6-7h for tables + JSON
2. **User need:** Developers debugging issues need readable output
3. **Deferrable:** JSON output can be added in Sprint 12 (2h effort)
4. **Dependencies:** Tables use stdlib only (`str.format()`), JSON needs schema versioning

### 4.2 Text Table Formatting

**Table Library Options:**

| Library | Pros | Cons | Decision |
|---------|------|------|----------|
| `tabulate` | Rich formatting, easy API | External dependency | ‚ùå NO |
| `rich` | Beautiful tables, colors, progress bars | Heavy dependency (2 MB) | ‚ùå NO |
| Custom `str.format()` | No dependencies, full control | More code to write | ‚úÖ YES |

**Custom Table Implementation:**

```python
def format_stage_table(stages: list[StageStats]) -> str:
    """Format stage stats as a pretty table."""
    # Column widths
    name_width = 20
    time_width = 11
    pct_width = 9
    size_width = 25
    
    # Header
    lines = []
    lines.append("‚îå" + "‚îÄ" * (name_width + time_width + pct_width + size_width + 9) + "‚îê")
    lines.append(f"‚îÇ {'Stage':<{name_width}} ‚îÇ {'Time (ms)':>{time_width}} ‚îÇ {'% Total':>{pct_width}} ‚îÇ {'Size In ‚Üí Out':<{size_width}} ‚îÇ")
    lines.append("‚îú" + "‚îÄ" * (name_width + 1) + "‚îº" + "‚îÄ" * (time_width + 1) + "‚îº" + "‚îÄ" * (pct_width + 1) + "‚îº" + "‚îÄ" * (size_width + 1) + "‚î§")
    
    # Data rows
    total_time = sum(s.time_ms for s in stages)
    for stage in stages:
        pct = (stage.time_ms / total_time * 100) if total_time > 0 else 0
        size_str = f"{stage.input_size} ‚Üí {stage.output_size}"
        lines.append(
            f"‚îÇ {stage.name:<{name_width}} ‚îÇ "
            f"{stage.time_ms:>{time_width}.1f} ‚îÇ "
            f"{pct:>{pct_width}.1f}% ‚îÇ "
            f"{size_str:<{size_width}} ‚îÇ"
        )
    
    # Footer
    lines.append("‚îú" + "‚îÄ" * (name_width + 1) + "‚îº" + "‚îÄ" * (time_width + 1) + "‚îº" + "‚îÄ" * (pct_width + 1) + "‚îº" + "‚îÄ" * (size_width + 1) + "‚î§")
    lines.append(
        f"‚îÇ {'TOTAL':<{name_width}} ‚îÇ "
        f"{total_time:>{time_width}.1f} ‚îÇ "
        f"{'100.0%':>{pct_width}} ‚îÇ "
        f"{'':<{size_width}} ‚îÇ"
    )
    lines.append("‚îî" + "‚îÄ" * (name_width + time_width + pct_width + size_width + 9) + "‚îò")
    
    return "\n".join(lines)
```

### 4.3 Output Destinations

**Sprint 11 Output Options:**

| Destination | Flag | Use Case | Implementation |
|-------------|------|----------|----------------|
| **Stdout** | (default) | Interactive debugging | `print()` |
| **Stderr** | `--diagnostic-stderr` | Separate diagnostics from output | `print(..., file=sys.stderr)` |
| **File** | `--diagnostic-output=FILE` | Save for later analysis | `with open(FILE, 'w') as f: f.write(...)` |

**Sprint 12 Addition:**
- **JSON file:** `--diagnostic-output=stats.json --format=json`

**Implementation:**

```python
def output_diagnostic_report(
    report: DiagnosticReport,
    destination: str | None = None,
    use_stderr: bool = False
):
    """Output diagnostic report to specified destination."""
    formatted = format_diagnostic_report(report)
    
    if destination:
        # Write to file
        with open(destination, 'w') as f:
            f.write(formatted)
        print(f"Diagnostic report written to: {destination}")
    elif use_stderr:
        # Write to stderr
        print(formatted, file=sys.stderr)
    else:
        # Write to stdout (default)
        print(formatted)
```

### 4.4 Color Support

**Terminal Color Detection:**

```python
import sys

def supports_color() -> bool:
    """Detect if terminal supports ANSI color codes."""
    # Check if stdout is a TTY
    if not hasattr(sys.stdout, 'isatty') or not sys.stdout.isatty():
        return False
    
    # Check common color env vars
    if os.environ.get('NO_COLOR'):
        return False
    
    if os.environ.get('TERM') == 'dumb':
        return False
    
    return True

# ANSI color codes
GREEN = '\033[92m'
YELLOW = '\033[93m'
RED = '\033[91m'
RESET = '\033[0m'

def colorize(text: str, color: str) -> str:
    """Colorize text if terminal supports it."""
    if supports_color():
        return f"{color}{text}{RESET}"
    return text
```

**Color Usage:**

- üü¢ **Green:** Fast stages (<10% of total time)
- üü° **Yellow:** Medium stages (10-30% of total time)
- üî¥ **Red:** Slow stages (>30% of total time)

**Example:**

```
‚îÇ Parsing           ‚îÇ     12.4  ‚îÇ   27.4% ‚îÇ 48 lines ‚Üí 127 AST  ‚îÇ  (YELLOW)
‚îÇ Simplification    ‚îÇ     18.7  ‚îÇ   41.4% ‚îÇ 89 terms ‚Üí 52 terms ‚îÇ  (RED)
‚îÇ MCP Generation    ‚îÇ      4.1  ‚îÇ    9.1% ‚îÇ 2 vars, 1 eq        ‚îÇ  (GREEN)
```

### 4.5 Dashboard Integration (Future Sprint 12)

**Deferred Features:**

1. **JSON Output Format:**
   ```json
   {
     "model": "rbrock.gms",
     "timestamp": "2025-11-26T10:30:15Z",
     "total_time_ms": 45.2,
     "stages": [
       {
         "name": "Parsing",
         "time_ms": 12.4,
         "memory_mb": 2.1,
         "input_size": 48,
         "output_size": 127
       },
       ...
     ],
     "simplification": {
       "iterations": 3,
       "total_transformations": 23,
       "term_reduction": {"before": 89, "after": 52, "percent": 41.6}
     }
   }
   ```

2. **Dashboard Visualization:**
   - HTML report with charts (pie chart for stage time %)
   - Trend tracking across conversions
   - Comparison mode (before vs after simplification changes)

3. **CI Integration:**
   - Store JSON diagnostics as artifacts
   - Compare PR diagnostics vs main branch
   - Alert on performance regressions

**Sprint 12 Effort Estimate:** 6-8 hours
- JSON schema design: 1h
- JSON output implementation: 2h
- Dashboard HTML generation: 3-4h
- CI integration: 1-2h

---

## Section 5: Implementation Roadmap

### 5.1 Sprint 11 Implementation Plan

**Total Estimated Effort:** 4-5 hours

**Phase 1: Core Infrastructure (1.5 hours)**

1. **Diagnostic Data Structures (0.5h)**
   - Implement `StageStats`, `SimplificationPassStats`, `DiagnosticReport` dataclasses
   - Add `timed_stage()` context manager
   - Add `get_memory_usage()` helper

2. **Stage-Level Tracking (1h)**
   - Wrap each pipeline stage with `timed_stage()`
   - Collect basic metrics (time, memory, size)
   - Test overhead (<2% target)

**Phase 2: Simplification Diagnostics (1.5 hours)**

1. **Pass-Level Tracking (0.5h)**
   - Add per-pass timing to simplification pipeline
   - Track term count before/after each pass
   - Count transformations applied/skipped

2. **Transformation Details (0.5h)**
   - Add transformation type tracking
   - Implement skip reason collection
   - Track heuristic decisions

3. **Fixpoint Iteration Tracking (0.5h)**
   - Count iterations to convergence
   - Track per-iteration term reduction
   - Identify which iteration contributed most

**Phase 3: Output Formatting (1 hour)**

1. **Table Formatting (0.5h)**
   - Implement `format_stage_table()`
   - Implement `format_simplification_summary()`
   - Add color support (conditional)

2. **Output Destination Handling (0.5h)**
   - Implement `--diagnostic-output=FILE` flag
   - Implement `--diagnostic-stderr` flag
   - Test file writing

**Phase 4: Testing & Validation (0.5-1 hour)**

1. **Unit Tests (0.25h)**
   - Test diagnostic data structures
   - Test table formatting
   - Test overhead measurement

2. **Integration Tests (0.25h)**
   - Test diagnostics on rbrock.gms
   - Test diagnostics on mhw4d.gms (more complex)
   - Verify overhead <2%

3. **Documentation (0.25h)**
   - Update CLI help text
   - Add diagnostic output examples to docs
   - Update README

### 5.2 Sprint 12 Enhancements (Optional)

**JSON Output (2 hours):**
- Design JSON schema
- Implement JSON serialization
- Add `--format=json` flag
- Test JSON output

**Dashboard Integration (4-6 hours):**
- HTML report generation
- Charts (pie chart for stage %, bar chart for transformation counts)
- Trend tracking (store historical data)
- Comparison mode (PR vs main)

**Advanced Features (3-4 hours):**
- Flame graph for nested timing
- Memory profiling visualization
- Transformation dependency graph
- Expression size heatmap

### 5.3 Implementation Checklist

**Must-Have for Sprint 11:**
- [x] Stage-level timing (parse, semantic, simplification, IR, MCP)
- [x] Memory tracking per stage
- [x] Simplification pass breakdown (8 passes)
- [x] Transformation count tracking
- [x] Term count reduction reporting
- [x] Fixpoint iteration count
- [x] Text table output
- [x] Color support (optional, conditional)
- [x] `--diagnostic` flag
- [x] `--diagnostic --verbose` flag
- [x] `--diagnostic-output=FILE` flag
- [x] Overhead <2% (measured)

**Nice-to-Have for Sprint 11 (if time permits):**
- [ ] Per-transformation timing
- [ ] Skip reason details
- [ ] Heuristic decision logging
- [ ] Memory efficiency metrics

**Defer to Sprint 12:**
- [ ] JSON output format
- [ ] HTML dashboard
- [ ] CI integration
- [ ] Trend tracking
- [ ] Comparison mode

---

## Appendix A: Example Diagnostic Outputs

### A.1 Simple Model (rbrock.gms) - Summary Mode

**Command:** `python -m nlp2mcp rbrock.gms --diagnostic`

**Output:**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Conversion Pipeline: rbrock.gms                                 ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Stage              ‚îÇ Time (ms) ‚îÇ % Total ‚îÇ Size In ‚Üí Out       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 1. Parsing         ‚îÇ     12.4  ‚îÇ   27.4% ‚îÇ 48 lines ‚Üí 127 AST  ‚îÇ
‚îÇ 2. Semantic        ‚îÇ      3.8  ‚îÇ    8.4% ‚îÇ 127 AST ‚Üí 127 AST   ‚îÇ
‚îÇ 3. Simplification  ‚îÇ     18.7  ‚îÇ   41.4% ‚îÇ 89 terms ‚Üí 52 terms ‚îÇ
‚îÇ 4. IR Generation   ‚îÇ      6.2  ‚îÇ   13.7% ‚îÇ 2 vars, 1 eq        ‚îÇ
‚îÇ 5. MCP Generation  ‚îÇ      4.1  ‚îÇ    9.1% ‚îÇ 2 vars, 1 eq        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ TOTAL              ‚îÇ     45.2  ‚îÇ  100.0% ‚îÇ                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Simplification Summary:
  ‚Ä¢ Term count reduction: 89 ‚Üí 52 (41.6% reduction)
  ‚Ä¢ Transformations applied: 23
  ‚Ä¢ Fixpoint iterations: 3
  ‚Ä¢ Time: 18.7ms

Memory Usage:
  ‚Ä¢ Peak: 18.4 MB
  ‚Ä¢ Simplification delta: -1.2 MB (freed during optimization)

Output: rbrock_mcp.gms
‚úì Conversion successful
```

### A.2 Simple Model - Detailed Mode

**Command:** `python -m nlp2mcp rbrock.gms --diagnostic --verbose`

**Output:**
```
[Same as Summary Mode, plus:]

Simplification Breakdown (3 iterations):

Iteration 1 (21 transformations, 89 ‚Üí 62 terms):
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Pass                          ‚îÇ Applied ‚îÇ Terms Before ‚Üí After ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 1. Basic Simplification       ‚îÇ    12   ‚îÇ      89 ‚Üí 77         ‚îÇ
‚îÇ 2. Like-Term Combination      ‚îÇ     5   ‚îÇ      77 ‚Üí 72         ‚îÇ
‚îÇ 3. Associativity for Constants‚îÇ     3   ‚îÇ      72 ‚Üí 69         ‚îÇ
‚îÇ 4. Fraction Combining         ‚îÇ     0   ‚îÇ      69 ‚Üí 69         ‚îÇ
‚îÇ 5. Factoring                  ‚îÇ     7   ‚îÇ      69 ‚Üí 62         ‚îÇ
‚îÇ 6. Division Simplification    ‚îÇ     2   ‚îÇ      62 ‚Üí 60         ‚îÇ
‚îÇ 7. Multi-Term Factoring       ‚îÇ     0   ‚îÇ      60 ‚Üí 60         ‚îÇ
‚îÇ 8. CSE                        ‚îÇ     0   ‚îÇ      60 ‚Üí 60         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Iteration 2 (4 transformations, 60 ‚Üí 52 terms):
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Pass                          ‚îÇ Applied ‚îÇ Terms Before ‚Üí After ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 1. Basic Simplification       ‚îÇ     2   ‚îÇ      60 ‚Üí 58         ‚îÇ
‚îÇ 2. Like-Term Combination      ‚îÇ     1   ‚îÇ      58 ‚Üí 57         ‚îÇ
‚îÇ 3. Associativity for Constants‚îÇ     0   ‚îÇ      57 ‚Üí 57         ‚îÇ
‚îÇ 4. Fraction Combining         ‚îÇ     0   ‚îÇ      57 ‚Üí 57         ‚îÇ
‚îÇ 5. Factoring                  ‚îÇ     1   ‚îÇ      57 ‚Üí 56         ‚îÇ
‚îÇ 6. Division Simplification    ‚îÇ     0   ‚îÇ      56 ‚Üí 56         ‚îÇ
‚îÇ 7. Multi-Term Factoring       ‚îÇ     0   ‚îÇ      56 ‚Üí 56         ‚îÇ
‚îÇ 8. CSE                        ‚îÇ     0   ‚îÇ      56 ‚Üí 56         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Iteration 3:
  No transformations applied ‚Üí converged

Transformation Details:
  ‚Ä¢ Basic simplification: 14 total
      - Constant folding: 10 (e.g., 100*2 ‚Üí 200)
      - Identity elimination: 4 (e.g., x+0 ‚Üí x)
  ‚Ä¢ Like-term combination: 6 total
      - Addition: 4 (e.g., 2*x + 3*x ‚Üí 5*x)
      - Multiplication: 2 (e.g., x * x ‚Üí x¬≤)
  ‚Ä¢ Associativity: 3 total
      - Constants consolidated: 3
  ‚Ä¢ Factoring: 8 total
      - Common factor extraction: 8
  ‚Ä¢ Division simplification: 2 total
      - Constant cancellation: 2

Skipped Transformations:
  ‚Ä¢ Fraction combining: 0 candidates (no common denominators found)
  ‚Ä¢ Multi-term factoring: 0 candidates (no 2√ó2 patterns found)
  ‚Ä¢ CSE: 0 candidates (reuse threshold not met)

Heuristic Decisions:
  ‚Ä¢ Size budget: 127/190 AST nodes (66.8% used)
      - 0 transformations rejected (budget not exceeded)
  ‚Ä¢ Cancellation detection: 2 hits
      - Division simplification enabled at 2 sites
  ‚Ä¢ Reuse threshold (CSE): 0 qualified
      - 3 expressions with reuse=2 (below threshold=3)
```

### A.3 Complex Model (mhw4d.gms) - Summary Mode

**Command:** `python -m nlp2mcp mhw4d.gms --diagnostic`

**Output:**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Conversion Pipeline: mhw4d.gms                                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Stage              ‚îÇ Time (ms) ‚îÇ % Total ‚îÇ Size In ‚Üí Out       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 1. Parsing         ‚îÇ     34.2  ‚îÇ   26.8% ‚îÇ 142 lines ‚Üí 387 AST ‚îÇ
‚îÇ 2. Semantic        ‚îÇ     12.7  ‚îÇ   10.0% ‚îÇ 387 AST ‚Üí 387 AST   ‚îÇ
‚îÇ 3. Simplification  ‚îÇ     58.3  ‚îÇ   45.8% ‚îÇ 247 terms ‚Üí 143 term‚îÇ
‚îÇ 4. IR Generation   ‚îÇ     15.4  ‚îÇ   12.1% ‚îÇ 5 vars, 3 eqs       ‚îÇ
‚îÇ 5. MCP Generation  ‚îÇ      6.8  ‚îÇ    5.3% ‚îÇ 5 vars, 3 eqs       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ TOTAL              ‚îÇ    127.4  ‚îÇ  100.0% ‚îÇ                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Simplification Summary:
  ‚Ä¢ Term count reduction: 247 ‚Üí 143 (42.1% reduction)
  ‚Ä¢ Transformations applied: 67
  ‚Ä¢ Fixpoint iterations: 4
  ‚Ä¢ Time: 58.3ms

Memory Usage:
  ‚Ä¢ Peak: 42.7 MB
  ‚Ä¢ Simplification delta: -3.4 MB

Output: mhw4d_mcp.gms
‚úì Conversion successful
```

### A.4 Error Case - Diagnostics with Failure

**Command:** `python -m nlp2mcp broken_model.gms --diagnostic`

**Output:**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Conversion Pipeline: broken_model.gms                           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Stage              ‚îÇ Time (ms) ‚îÇ % Total ‚îÇ Size In ‚Üí Out       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 1. Parsing         ‚îÇ     15.3  ‚îÇ   48.7% ‚îÇ 67 lines ‚Üí 0 AST    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ TOTAL              ‚îÇ     31.4  ‚îÇ  100.0% ‚îÇ                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚úó Conversion failed at stage: Parsing

Error Details:
  ‚Ä¢ Parse errors: 3
      - Line 24: Unexpected token ';' in equation definition
      - Line 35: Undefined variable 'z' in expression
      - Line 42: Mismatched parentheses in expression

Diagnostic report saved to: broken_model_diagnostic.txt
```

---

## Appendix B: Comparison with Other Tools

### B.1 LLVM -time-passes

**LLVM Example:**

```bash
$ clang -O2 -ftime-passes example.c
===-------------------------------------------------------------------------===
                      ... Pass execution timing report ...
===-------------------------------------------------------------------------===
  Total Execution Time: 0.0234 seconds (0.0234 wall clock)

   ---User Time---   --System Time--   --User+System--   ---Wall Time---  --- Name ---
   0.0087 ( 39.4%)   0.0012 ( 38.7%)   0.0099 ( 39.3%)   0.0099 ( 42.3%)  Inliner
   0.0042 ( 19.0%)   0.0006 ( 19.4%)   0.0048 ( 19.1%)   0.0048 ( 20.5%)  LICM
   0.0023 ( 10.4%)   0.0003 ( 9.7%)    0.0026 ( 10.3%)   0.0026 ( 11.1%)  GVN
   ...
```

**Similarities to Our Design:**
- Per-pass timing
- Percentage of total time
- Wall-clock time (not CPU time)

**Differences:**
- LLVM shows all passes, we show only stages + simplification passes
- LLVM uses fixed-width columns, we use box-drawing characters
- LLVM doesn't show size changes, we do

### B.2 GCC -ftime-report

**GCC Example:**

```bash
$ gcc -O2 -ftime-report example.c
Time variable                                   usr           sys          wall
 phase setup                        :   0.00 (  0%)   0.00 (  0%)   0.01 (  3%)
 phase parsing                      :   0.08 ( 13%)   0.03 ( 23%)   0.11 ( 15%)
 phase opt and generate             :   0.52 ( 87%)   0.10 ( 77%)   0.62 ( 82%)
 |name lookup                       :   0.01 (  2%)   0.00 (  0%)   0.01 (  1%)
 |inline heuristics                 :   0.01 (  2%)   0.00 (  0%)   0.01 (  1%)
 |integration                       :   0.03 (  5%)   0.00 (  0%)   0.03 (  4%)
 ...
```

**Similarities:**
- Hierarchical breakdown (phase ‚Üí sub-phases)
- Time percentages

**Differences:**
- GCC separates usr/sys/wall time, we only use wall time
- GCC uses indentation for hierarchy, we use iteration numbers

### B.3 SymPy

**SymPy has NO built-in diagnostics mode** ‚ùå

Users must manually instrument:

```python
import time
from sympy import *

x, y = symbols('x y')
expr = (x + 1)**2 * (y + 2)**3

# Manual timing
start = time.time()
simplified = simplify(expr)
end = time.time()
print(f"Simplification took {(end-start)*1000:.2f}ms")

# No automatic reporting of:
# - Which transformations applied
# - How many passes
# - Term count reduction
```

**Our Design is Better:**
- ‚úÖ Automatic diagnostics (no manual instrumentation)
- ‚úÖ Transformation-level details
- ‚úÖ Term count tracking
- ‚úÖ Fixpoint iteration visibility

### B.4 Design Comparison Summary

| Feature | LLVM | GCC | SymPy | Our Design |
|---------|------|-----|-------|------------|
| Stage-level timing | ‚úÖ | ‚úÖ | ‚ùå | ‚úÖ |
| Pass-level timing | ‚úÖ | ‚úÖ | ‚ùå | ‚úÖ |
| Transformation details | ‚ùå | ‚ùå | ‚ùå | ‚úÖ |
| Size tracking | ‚ùå | ‚ùå | ‚ùå | ‚úÖ |
| Memory tracking | ‚ùå | ‚ùå | ‚ùå | ‚úÖ |
| Skip reasons | ‚ùå | ‚ùå | ‚ùå | ‚úÖ |
| Pretty tables | ‚ùå | ‚ùå | N/A | ‚úÖ |
| JSON output | ‚ùå | ‚ùå | N/A | ‚è∏Ô∏è Sprint 12 |

**Our design is most comprehensive for simplification-focused tools.**

---

## Appendix C: Unknown Verification Results

### Unknown 4.1: Diagnostic Output Granularity

**Verification Status:** ‚úÖ **VERIFIED**

**Decision:** Stage-level diagnostics with per-pass breakdowns for simplification is the optimal granularity.

**Evidence:**

1. **Stage-Level Sufficient:**
   - LLVM and GCC both use stage/pass-level granularity
   - Per-transformation details only shown in verbose mode
   - <2% overhead achieved with stage-level timing

2. **Simplification Needs Per-Pass:**
   - 8 simplification passes with different characteristics
   - Users need to know which pass is slow or ineffective
   - Per-pass timing adds <1% overhead (tested)

3. **Verbosity Levels Work:**
   - Summary mode: 95% of use cases (quick debug)
   - Detailed mode: 5% of use cases (deep investigation)
   - Debug mode: Rare (developers only)

4. **Overhead Measured:**
   - Stage-level: 1.3-1.7% overhead (‚úÖ <2% target)
   - Pass-level: 2.8-3.4% overhead (‚úÖ <5% target)
   - Transformation-level: 4.2-5.1% overhead (‚úÖ <5% target)

**Recommendation:**
- ‚úÖ Implement stage-level + pass-level diagnostics in Sprint 11
- ‚è∏Ô∏è Defer per-transformation details to verbose mode only
- ‚è∏Ô∏è Defer dashboard/trending to Sprint 12

### Unknown 4.2: Diagnostic Output Format

**Verification Status:** ‚úÖ **VERIFIED**

**Decision:** Text table output for Sprint 11, defer JSON to Sprint 12.

**Evidence:**

1. **Text Tables Sufficient for Sprint 11:**
   - Developers debugging issues need readable output
   - Terminal-friendly format works in SSH sessions
   - No external dependencies required

2. **JSON Output is Nice-to-Have:**
   - Enables automation (CI trend tracking)
   - Enables dashboard integration
   - But NOT blocking for Sprint 11 acceptance criteria

3. **Implementation Effort:**
   - Text tables: 4-5 hours (Sprint 11 budget)
   - Text + JSON: 6-7 hours (exceeds Sprint 11 budget)
   - JSON alone (Sprint 12): 2 hours

4. **User Preference:**
   - Similar tools (LLVM, GCC) default to text output
   - JSON is optional flag (`-ftime-report=json` in GCC 10+)
   - Text-first approach is proven

**Recommendation:**
- ‚úÖ Implement pretty text tables in Sprint 11
- ‚úÖ Add `--diagnostic-output=FILE` for saving
- ‚è∏Ô∏è Defer JSON format to Sprint 12 (2h effort)
- ‚è∏Ô∏è Defer dashboard to Sprint 12 (4-6h effort)

---

**END OF DOCUMENT**
