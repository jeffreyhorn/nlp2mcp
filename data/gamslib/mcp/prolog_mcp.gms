$onText
Generated by nlp2mcp

This file contains the KKT (Karush-Kuhn-Tucker) conditions
for the original NLP model, transformed into MCP format.

KKT System Components:
  - Stationarity: ∇f + J^T λ + J^T ν - π^L + π^U = 0
  - Complementarity: g(x) ⊥ λ, h(x) = 0, bounds ⊥ π
  - Dual feasibility: λ, π^L, π^U ≥ 0
  - Primal feasibility: g(x) ≤ 0, h(x) = 0, lo ≤ x ≤ up
$offText

* ============================================
* Original Model Declarations
* ============================================

Sets
    i /food, 'h-industry', 'l-industry'/
    g(i) /food, 'l-industry'/
    k /labor, capital/
    h /workers, enterpr/
    t /'tech-1', 'tech-2', 'tech-3'/
;

Alias(i, j);
Alias(g, gp);

Parameters
    a(i,j) /food.food 0.06, food.'l-industry' 0.244, 'h-industry'.food 0.064, 'h-industry'.'h-industry' 0.42, 'h-industry'.'l-industry' 0.172, 'l-industry'.food 0.048, 'l-industry'.'h-industry' 0.247, 'l-industry'.'l-industry' 0.084, food.'h-industry' 0.0/
    d(i,k,t)
    bb(h,k) /workers.labor 0.9, workers.capital 0.1, enterpr.labor 0.1, enterpr.capital 0.9/
    x0(i,h) /food.workers 352.0, food.enterpr 430.0, 'l-industry'.workers 222.0, 'l-industry'.enterpr 292.0/
    b(k) /labor 3712.0, capital 5000.0/
    p0(i) /food 0.5942, 'h-industry' 1.6167, 'l-industry' 1.31077/
    y0(h)
    q0(i)
    gamma(g,h)
    beta(g,h)
    alpha(g,h)
    al(g,h)
    cl(g,h)
    s(g,gp,h)
    an(g,h)
    eta(g,gp,h)
    epsi(i,h) /food.workers 0.8, food.enterpr 0.6, 'l-industry'.workers 1.14, 'l-industry'.enterpr 1.26/
    etest(h)
    htest(g,h)
    ctest(g,h)
    wp(g)
;

Scalars
    r0 /0.0/
    omega /-2.0/
;

* Fix random seed for deterministic MCP evaluation
execseed = 12345;

y0(h) = sum(g, x0(g,h) * p0(g));
r0 = sum(h, y0(h)) / sum(k, b(k));
gamma(g,h) = x0(g,h) + beta(g,h) * y0(h) / p0(g) / omega;
beta(g,h) = epsi(g,h) * alpha(g,h);
alpha(g,h) = p0(g) * x0(g,h) / y0(h);
al(g,h) = x0(g,h) - sum(gp, s(g,gp,h) * p0(gp)) - cl(g,h) * y0(h);
cl(g,h) = epsi(g,h) * x0(g,h) / y0(h);
s(g,gp,h) = eta(g,gp,h) * x0(g,h) / p0(gp);
an(g,h) = x0(g,h) / prod(gp, p0(gp) ** eta(g,gp,h)) / y0(h) ** epsi(g,h);
eta(g,gp,h) = ((-1) * (gamma(gp, h))) * p0(gp) * beta(g,h) / p0(g) / x0(g,h);
eta(g,g,h) = gamma(g, h) * (1 - beta(g,h)) / x0(g,h) - 1;
epsi(g,h) = epsi(g,h) / sum(gp, epsi(gp,h) * alpha(gp,h));
etest(h) = sum(g, epsi(g,h) * alpha(g,h)) - 1;
htest(g,h) = sum(gp, eta(g,gp,h)) + epsi(g,h);
ctest(g,h) = sum(gp, alpha(gp,h) * eta(gp,g,h)) + alpha(g,h);
wp(g) = sum(h, x0(g,h) * p0(g)) / sum(h, y0(h));

* ============================================
* Variables (Primal + Multipliers)
* ============================================

* Primal variables: Original decision variables from the NLP
* Multipliers:
*   ν (nu_*): Free multipliers for equality constraints
*   λ (lam_*): Positive multipliers for inequality constraints
*   π^L (piL_*): Positive multipliers for lower bounds
*   π^U (piU_*): Positive multipliers for upper bounds

Variables
    z
;

Positive Variables
    p(i)
    x(i,h)
    r(k)
    q(i,t)
    y(h)
    lam_cb(i)
    lam_rc(k)
    lam_de(g,h)
    lam_dl(g,h)
    lam_dn(g,h)
    lam_bc(h)
    lam_id(h)
    lam_mp(i,t)
    piL_p(i)
;

* ============================================
* Variable Initialization
* ============================================

* Initialize variables to avoid division by zero during model generation.
* Variables appearing in denominators (from log, 1/x derivatives) need
* non-zero initial values.
* POSITIVE variables with explicit .l values are
* clamped to min(max(value, 1e-6), upper_bound). Others are set to 1.

p.l("food") = 0.2;
p.l("h-industry") = 0.2;
p.l("l-industry") = 0.2;
p.l(i) = min(max(p.l(i), 1e-6), p.up(i));
x.l(i,h) = 1;
r.l(k) = 1;
q.l(i,t) = 1;
y.l(h) = 1;

* ============================================
* Equations
* ============================================

* Stationarity: One equation per primal variable (except objvar)
* Complementarity: Equations for inequalities and bounds
* Equality constraints: Original equality constraints

Equations
    stat_p(i)
    stat_q(i,t)
    stat_r(k)
    stat_x(i,h)
    stat_y(h)
    comp_bc(h)
    comp_cb(i)
    comp_de(g,h)
    comp_dl(g,h)
    comp_dn(g,h)
    comp_id(h)
    comp_mp(i,t)
    comp_rc(k)
    comp_lo_p(i)
    zdef
;

* ============================================
* Equation Definitions
* ============================================

* Stationarity equations
stat_p(i).. ((-1) * sum(h, x(i,h))) + sum(gp, sum((g,h), ((-1) * ((p(g) * beta(g,h) * ((-1) * (gamma(gp, h))) - beta(g,h) * (y(h) - sum(gp, gamma(gp, h) * p(gp)))) / p(g) ** 2)) * lam_de(g,h))) + sum(gp, sum((g,h), ((-1) * s(g,gp,h)) * lam_dl(g,h))) + sum((g,h), ((-1) * (y(h) ** epsi(i,h) * an(g,h) * prod(gp, p(gp) ** eta(g,gp,h)) * sum(gp, p(gp) ** eta(g,gp,h) * eta(g,gp,h) / p(gp) / p(gp) ** eta(g,gp,h)))) * lam_dn(g,h)) + sum(h, x(i,h) * lam_bc(h)) + sum(t, (1 - a(i,i)) * lam_mp(i,t)) - piL_p(i) =E= 0;
stat_q(i,t).. ((-1) * (1 - a(i,i))) * lam_cb(i) + sum(k, d(i,k,t) * lam_rc(k)) =E= 0;
stat_r(k).. b(k) + sum(h, ((-1) * (bb(h,k) * b(k))) * lam_id(h)) + sum((i,t), ((-1) * d(i,k,t)) * lam_mp(i,t)) =E= 0;
stat_x(i,h).. ((-1) * p(i)) + 1$g(i) * lam_cb(i) + sum(g, lam_de(g,h)) + sum(g, lam_dl(g,h)) + sum(g, lam_dn(g,h)) + p(i) * lam_bc(h) =E= 0;
stat_y(h).. sum(g, ((-1) * (p(g) * beta(g,h) / p(g) ** 2)) * lam_de(g,h)) + sum(g, ((-1) * cl(g,h)) * lam_dl(g,h)) + sum(i, sum(g, ((-1) * (an(g,h) * prod(gp, p(gp) ** eta(g,gp,h)) * y(h) ** epsi(i,h) * epsi(i,h) / y(h))) * lam_dn(g,h))) - lam_bc(h) + lam_id(h) =E= 0;

* Inequality complementarity equations
comp_bc(h).. ((-1) * (sum(g, x(g,h) * p(g)) - y(h))) =G= 0;
comp_cb(i).. ((-1) * (sum(h$(g(i)), x(i,h)) - sum(t, q(i,t) - sum(j, a(i,j) * q(j,t))))) =G= 0;
comp_de(g,h).. ((-1) * (x(g,h) - (gamma(g, h) + beta(g,h) * (y(h) - sum(gp, gamma(gp, h) * p(gp))) / p(g)))) =G= 0;
comp_dl(g,h).. ((-1) * (x(g,h) - (al(g,h) + sum(gp, s(g,gp,h) * p(gp)) + cl(g,h) * y(h)))) =G= 0;
comp_dn(g,h).. ((-1) * (x(g,h) - an(g,h) * prod(gp, p(gp) ** eta(g,gp,h)) * y(h) ** epsi(g,h))) =G= 0;
comp_id(h).. ((-1) * (y(h) - sum(k, bb(h,k) * b(k) * r(k)))) =G= 0;
comp_mp(i,t).. ((-1) * (p(i) - (sum(j, a(j,i) * p(j)) + sum(k, d(i,k,t) * r(k))))) =G= 0;
comp_rc(k).. ((-1) * (sum((i,t), d(i,k,t) * q(i,t)) - b(k))) =G= 0;

* Lower bound complementarity equations
comp_lo_p(i).. p(i) - 0.2 =G= 0;

* Original equality equations
zdef.. z =E= sum((g,h), x(g,h) * p(g)) - sum(k, b(k) * r(k));


* ============================================
* Model MCP Declaration
* ============================================

* Each line pairs an equation with a variable:
*   equation.variable
*
* This defines the complementarity problem:
*   equation ⊥ variable
*
* Meaning: equation = 0 if variable > 0
*          equation ≥ 0 if variable = 0

Model mcp_model /
    stat_p.p,
    stat_q.q,
    stat_r.r,
    stat_x.x,
    stat_y.y,
    comp_bc.lam_bc,
    comp_cb.lam_cb,
    comp_de.lam_de,
    comp_dl.lam_dl,
    comp_dn.lam_dn,
    comp_id.lam_id,
    comp_mp.lam_mp,
    comp_rc.lam_rc,
    zdef.z,
    comp_lo_p.piL_p
/;

* ============================================
* Solve Statement
* ============================================

Solve mcp_model using MCP;

Scalar nlp2mcp_obj_val;
nlp2mcp_obj_val = z.l;
Display nlp2mcp_obj_val;